{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86523752",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f985e910",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/aug_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6309ef52",
   "metadata": {},
   "source": [
    "# label 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe05725d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>자연</td>\n",
       "      <td>자연관광지</td>\n",
       "      <td>항구/포구</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>자연</td>\n",
       "      <td>자연관광지</td>\n",
       "      <td>섬</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>자연</td>\n",
       "      <td>자연관광지</td>\n",
       "      <td>자연휴양림</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>자연</td>\n",
       "      <td>자연관광지</td>\n",
       "      <td>해수욕장</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>자연</td>\n",
       "      <td>자연관광지</td>\n",
       "      <td>산</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>쇼핑</td>\n",
       "      <td>쇼핑</td>\n",
       "      <td>상설시장</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>쇼핑</td>\n",
       "      <td>쇼핑</td>\n",
       "      <td>공예,공방</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>쇼핑</td>\n",
       "      <td>쇼핑</td>\n",
       "      <td>백화점</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>쇼핑</td>\n",
       "      <td>쇼핑</td>\n",
       "      <td>면세점</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>쇼핑</td>\n",
       "      <td>쇼핑</td>\n",
       "      <td>특산물판매점</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    cat1   cat2    cat3 count\n",
       "0     자연  자연관광지   항구/포구   134\n",
       "1     자연  자연관광지       섬   111\n",
       "2     자연  자연관광지   자연휴양림   118\n",
       "3     자연  자연관광지    해수욕장   207\n",
       "4     자연  자연관광지       산   239\n",
       "..   ...    ...     ...   ...\n",
       "123   쇼핑     쇼핑    상설시장   270\n",
       "124   쇼핑     쇼핑   공예,공방    41\n",
       "125   쇼핑     쇼핑     백화점    16\n",
       "126   쇼핑     쇼핑     면세점    18\n",
       "127   쇼핑     쇼핑  특산물판매점    37\n",
       "\n",
       "[128 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df = pd.DataFrame(columns=['cat1','cat2','cat3','count'])\n",
    "for n_cat1 in df['cat1'].unique() :\n",
    "    cat2 = df[df['cat1'] == n_cat1]['cat2'].unique()\n",
    "    for n_cat2 in cat2 :\n",
    "        cat3  = df[df['cat1'] == n_cat1][df['cat2'] == n_cat2]['cat3'].unique()\n",
    "        for n_cat3 in cat3 :\n",
    "            cnt = len(df[df['cat1'] == n_cat1][df['cat2'] == n_cat2][df['cat3'] == n_cat3])\n",
    "            n = pd.DataFrame([[n_cat1, n_cat2, n_cat3, cnt]], columns=['cat1', 'cat2', 'cat3', 'count'])\n",
    "            label_df = pd.concat([label_df, n], ignore_index=True)\n",
    "\n",
    "label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3ed826c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'항구/포구': 0,\n",
       " '섬': 1,\n",
       " '자연휴양림': 2,\n",
       " '해수욕장': 3,\n",
       " '산': 4,\n",
       " '수목원': 5,\n",
       " '강': 6,\n",
       " '자연생태관광지': 7,\n",
       " '계곡': 8,\n",
       " '폭포': 9,\n",
       " '국립공원': 10,\n",
       " '해안절경': 11,\n",
       " '호수': 12,\n",
       " '동굴': 13,\n",
       " '도립공원': 14,\n",
       " '군립공원': 15,\n",
       " '약수터': 16,\n",
       " '등대': 17,\n",
       " '희귀동.식물': 18,\n",
       " '기암괴석': 19,\n",
       " '골프': 20,\n",
       " '야영장,오토캠핑장': 21,\n",
       " '스키(보드) 렌탈샵': 22,\n",
       " '자동차경주': 23,\n",
       " '자전거하이킹': 24,\n",
       " '썰매장': 25,\n",
       " '승마': 26,\n",
       " '트래킹': 27,\n",
       " '수련시설': 28,\n",
       " '카지노': 29,\n",
       " '번지점프': 30,\n",
       " '카트': 31,\n",
       " 'MTB': 32,\n",
       " '스케이트': 33,\n",
       " '인라인(실내 인라인 포함)': 34,\n",
       " '사격장': 35,\n",
       " 'ATV': 36,\n",
       " '빙벽등반': 37,\n",
       " '스키/스노보드': 38,\n",
       " '복합 레포츠': 39,\n",
       " '요트': 40,\n",
       " '래프팅': 41,\n",
       " '민물낚시': 42,\n",
       " '바다낚시': 43,\n",
       " '수영': 44,\n",
       " '카약/카누': 45,\n",
       " '윈드서핑/제트스키': 46,\n",
       " '스노쿨링/스킨스쿠버다이빙': 47,\n",
       " '스카이다이빙': 48,\n",
       " '헹글라이딩/패러글라이딩': 49,\n",
       " '수상레포츠': 50,\n",
       " '한식': 51,\n",
       " '일식': 52,\n",
       " '바/까페': 53,\n",
       " '채식전문점': 54,\n",
       " '중식': 55,\n",
       " '서양식': 56,\n",
       " '패밀리레스토랑': 57,\n",
       " '클럽': 58,\n",
       " '일반축제': 59,\n",
       " '문화관광축제': 60,\n",
       " '유적지/사적지': 61,\n",
       " '성': 62,\n",
       " '안보관광': 63,\n",
       " '사찰': 64,\n",
       " '종교성지': 65,\n",
       " '고택': 66,\n",
       " '고궁': 67,\n",
       " '민속마을': 68,\n",
       " '문': 69,\n",
       " '생가': 70,\n",
       " '전시관': 71,\n",
       " '미술관/화랑': 72,\n",
       " '박물관': 73,\n",
       " '도서관': 74,\n",
       " '공연장': 75,\n",
       " '기념관': 76,\n",
       " '문화전수시설': 77,\n",
       " '문화원': 78,\n",
       " '외국문화원': 79,\n",
       " '대형서점': 80,\n",
       " '영화관': 81,\n",
       " '학교': 82,\n",
       " '컨벤션센터': 83,\n",
       " '관광단지': 84,\n",
       " '공원': 85,\n",
       " '유원지': 86,\n",
       " '온천/욕장/스파': 87,\n",
       " '테마공원': 88,\n",
       " '유람선/잠수함관광': 89,\n",
       " '이색찜질방': 90,\n",
       " '헬스투어': 91,\n",
       " '컨벤션': 92,\n",
       " '박람회': 93,\n",
       " '기타행사': 94,\n",
       " '전통공연': 95,\n",
       " '대중콘서트': 96,\n",
       " '연극': 97,\n",
       " '뮤지컬': 98,\n",
       " '클래식음악회': 99,\n",
       " '이색거리': 100,\n",
       " '농.산.어촌 체험': 101,\n",
       " '이색체험': 102,\n",
       " '기념탑/기념비/전망대': 103,\n",
       " '유명건물': 104,\n",
       " '동상': 105,\n",
       " '다리/대교': 106,\n",
       " '분수': 107,\n",
       " '터널': 108,\n",
       " '기타': 109,\n",
       " '식음료': 110,\n",
       " '발전소': 111,\n",
       " '모텔': 112,\n",
       " '한옥스테이': 113,\n",
       " '펜션': 114,\n",
       " '게스트하우스': 115,\n",
       " '홈스테이': 116,\n",
       " '콘도미니엄': 117,\n",
       " '민박': 118,\n",
       " '유스호스텔': 119,\n",
       " '서비스드레지던스': 120,\n",
       " '전문상가': 121,\n",
       " '5일장': 122,\n",
       " '상설시장': 123,\n",
       " '공예,공방': 124,\n",
       " '백화점': 125,\n",
       " '면세점': 126,\n",
       " '특산물판매점': 127}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_encoder = {v : i for i, v in enumerate(label_df.loc[:, 'cat3'].values)}\n",
    "cat_encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503b8382",
   "metadata": {},
   "source": [
    "# FSL에 학습 규격에 맞춰서 이미지 이동"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56ebca3",
   "metadata": {},
   "source": [
    "### 경로 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "91e6bf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = './data/fsl_img'\n",
    "os.makedirs(root_path, exist_ok=True)\n",
    "\n",
    "for i, label_name in enumerate(label_df['cat3'].values) :\n",
    "    fold_path = os.path.join(root_path, str(i))#label_name)\n",
    "    os.makedirs(fold_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdebe23",
   "metadata": {},
   "source": [
    "### 이미지 이동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f969a56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 17345/17345 [00:18<00:00, 955.26it/s]\n"
     ]
    }
   ],
   "source": [
    "# df.iloc[0]\n",
    "source_root_path = './data'\n",
    "dest_root_path = './data/fsl_img'\n",
    "\n",
    "for i in tqdm(range(len(df))):\n",
    "    img_path = os.path.join(source_root_path, df.iloc[i]['img_path'])\n",
    "    label = cat_encoder[df.iloc[i]['cat3']] #df.iloc[i]['cat3'] \n",
    "    img_name = df.iloc[i]['id']\n",
    "    dest_path = os.path.join(dest_root_path, str(label), img_name+'.jpg')\n",
    "    \n",
    "    # copy\n",
    "    shutil.copyfile(img_path, dest_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e925b32",
   "metadata": {},
   "source": [
    "# FSL에 이용하는 json 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b227727",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "import json\n",
    "\n",
    "fsl_t = defaultdict(list)\n",
    "fsl_v = defaultdict(list)\n",
    "\n",
    "vaild_pick = random.sample([i for i in range(128)], 26)\n",
    "\n",
    "path = './data/fsl_img/*'\n",
    "label_list = glob(path)\n",
    "label_list.sort(key=lambda x: int(x.split('\\\\')[-1]))\n",
    "\n",
    "\n",
    "\n",
    "for idx, label in enumerate(label_list) :  \n",
    "    if idx in vaild_pick :\n",
    "        fsl_v['class_roots'].append(label)\n",
    "        fsl_v['class_names'].append(label.split('\\\\')[-1])\n",
    "\n",
    "    else :\n",
    "        fsl_t['class_roots'].append(label)\n",
    "        fsl_t['class_names'].append(label.split('\\\\')[-1])\n",
    "\n",
    "    \n",
    "with open('./data/fsl_train.json', 'w') as f:\n",
    "    json.dump(fsl_t, f, indent=2)\n",
    "    \n",
    "with open('./data/fsl_valid.json', 'w') as f:\n",
    "    json.dump(fsl_v, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2855ba2",
   "metadata": {},
   "source": [
    "# FSL configuration 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d471a3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import random\n",
    "from statistics import mean\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "import timm\n",
    "import os\n",
    "\n",
    "from easyfsl.methods.utils import evaluate\n",
    "from easydict import EasyDict\n",
    "\n",
    "args = EasyDict({'n_way' : 4, \n",
    "                 'n_shot' : 3, \n",
    "                 'n_query' : 6, \n",
    "                 'n_workers' : 6, \n",
    "                 'DEVICE' : \"cuda\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03f8f7b",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09e36553",
   "metadata": {},
   "outputs": [],
   "source": [
    "from easyfsl.datasets import CUB, CUSTOM\n",
    "from easyfsl.samplers import TaskSampler\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "n_tasks_per_epoch = 300\n",
    "n_validation_tasks = 100\n",
    "\n",
    "\n",
    "\n",
    "train_set = CUSTOM(split=\"data/fsl_train\", image_size=224 ,training=True)\n",
    "val_set = CUSTOM(split=\"data/fsl_valid\", image_size=224, training=False)\n",
    "\n",
    "train_sampler = TaskSampler(\n",
    "    train_set, \n",
    "    n_way=args.n_way, \n",
    "    n_shot=args.n_shot, \n",
    "    n_query=args.n_query, \n",
    "    n_tasks=n_tasks_per_epoch\n",
    ")\n",
    "val_sampler = TaskSampler(\n",
    "    val_set, \n",
    "    n_way=args.n_way, \n",
    "    n_shot=args.n_shot, \n",
    "    n_query=args.n_query, \n",
    "    n_tasks=n_validation_tasks\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_set,\n",
    "    batch_sampler=train_sampler,\n",
    "    num_workers=args.n_workers,\n",
    "    pin_memory=True,\n",
    "    collate_fn=train_sampler.episodic_collate_fn,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_set,\n",
    "    batch_sampler=val_sampler,\n",
    "    num_workers=args.n_workers,\n",
    "    pin_memory=True,\n",
    "    collate_fn=val_sampler.episodic_collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ef1182",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e62fc52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module) :\n",
    "    def __init__(self, name='efficientnetv2_rw_m', num_classes=0)  :\n",
    "        super(CNN, self).__init__()\n",
    "        self.model = timm.create_model(name, pretrained=True, num_classes=num_classes, global_pool='')\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.flatten = nn.Flatten(1)\n",
    "        \n",
    "    def forward(self, x) :\n",
    "        x = self.model.forward_features(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.flatten(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25e636fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from easyfsl.methods import PrototypicalNetworks, FewShotClassifier, TIM, RelationNetworks\n",
    "\n",
    "convolutional_network = CNN().to(args.DEVICE)\n",
    "few_shot_classifier = PrototypicalNetworks(convolutional_network).to(args.DEVICE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263d657b",
   "metadata": {},
   "source": [
    "# Episodic Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08fdd96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import SGD, Optimizer, AdamW, Adam\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "n_epochs = 30\n",
    "scheduler_milestones = [3, 6]\n",
    "scheduler_gamma = 0.1\n",
    "learning_rate = 1e-3\n",
    "\n",
    "\n",
    "train_optimizer = Adam(\n",
    "    few_shot_classifier.parameters(), lr=learning_rate, weight_decay=5e-4)#,  momentum=0.9)\n",
    "\n",
    "\n",
    "train_scheduler = MultiStepLR(\n",
    "    train_optimizer,\n",
    "    milestones=scheduler_milestones,\n",
    "    gamma=scheduler_gamma,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85a926b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_epoch(\n",
    "    model: FewShotClassifier, data_loader: DataLoader, optimizer: Optimizer\n",
    "):\n",
    "    all_loss = []\n",
    "    model.train()\n",
    "    with tqdm(\n",
    "        enumerate(data_loader), total=len(data_loader), desc=\"Training\"\n",
    "    ) as tqdm_train:\n",
    "        for episode_index, (\n",
    "            support_images,\n",
    "            support_labels,\n",
    "            query_images,\n",
    "            query_labels,\n",
    "            _,\n",
    "        ) in tqdm_train:\n",
    "            optimizer.zero_grad()\n",
    "            model.process_support_set(\n",
    "                support_images.to(args.DEVICE), support_labels.to(args.DEVICE)\n",
    "            )\n",
    "            classification_scores = model(query_images.to(args.DEVICE))\n",
    "\n",
    "            loss = criterion(classification_scores, query_labels.to(args.DEVICE))\n",
    "#             loss.requires_grad_(True)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            all_loss.append(loss.item())\n",
    "\n",
    "            tqdm_train.set_postfix(loss=mean(all_loss))\n",
    "\n",
    "    return mean(all_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17911b27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████| 300/300 [03:08<00:00,  1.59it/s, loss=0.889]\n",
      "Validation: 100%|████████████████████████████████████████████████████| 100/100 [00:17<00:00,  5.79it/s, accuracy=0.549]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ding ding ding! We found a new best model!\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████| 300/300 [03:01<00:00,  1.65it/s, loss=0.888]\n",
      "Validation: 100%|████████████████████████████████████████████████████| 100/100 [00:17<00:00,  5.87it/s, accuracy=0.486]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█████████                                                   | 45/300 [00:28<02:40,  1.59it/s, loss=0.88]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 21>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_e, n_epochs):\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 23\u001b[0m     average_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfew_shot_classifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_optimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m     validation_accuracy \u001b[38;5;241m=\u001b[39m evaluate(\n\u001b[0;32m     25\u001b[0m         few_shot_classifier, val_loader, device\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mDEVICE, tqdm_prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     26\u001b[0m     )\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m validation_accuracy \u001b[38;5;241m>\u001b[39m best_validation_accuracy:\n",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36mtraining_epoch\u001b[1;34m(model, data_loader, optimizer)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m#             loss.requires_grad_(True)\u001b[39;00m\n\u001b[0;32m     24\u001b[0m             loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 25\u001b[0m             \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m             all_loss\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m     29\u001b[0m             tqdm_train\u001b[38;5;241m.\u001b[39mset_postfix(loss\u001b[38;5;241m=\u001b[39mmean(all_loss))\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\torch-1.11\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:65\u001b[0m, in \u001b[0;36m_LRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m instance\u001b[38;5;241m.\u001b[39m_step_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     64\u001b[0m wrapped \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance, \u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\torch-1.11\\lib\\site-packages\\torch\\optim\\optimizer.py:88\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[1;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\torch-1.11\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[1;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\torch-1.11\\lib\\site-packages\\torch\\optim\\adam.py:141\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    138\u001b[0m             \u001b[38;5;66;03m# record the step after step update\u001b[39;00m\n\u001b[0;32m    139\u001b[0m             state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m--> 141\u001b[0m     \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[43m           \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[43m           \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m           \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[43m           \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[43m           \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[43m           \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m           \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m           \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[43m           \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[43m           \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m           \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[43m           \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\torch-1.11\\lib\\site-packages\\torch\\optim\\_functional.py:105\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    103\u001b[0m     denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(bias_correction2))\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 105\u001b[0m     denom \u001b[38;5;241m=\u001b[39m (\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(bias_correction2))\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[0;32m    109\u001b[0m step_size \u001b[38;5;241m=\u001b[39m lr \u001b[38;5;241m/\u001b[39m bias_correction1\n\u001b[0;32m    110\u001b[0m param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from easyfsl.methods.utils import evaluate\n",
    "\n",
    "start_e = 0\n",
    "best_e = None\n",
    "resum = False\n",
    "model_save_path = './ckpt/fsl/albumen_224_effi2_m_2'\n",
    "os.makedirs(model_save_path, exist_ok=True)\n",
    "\n",
    "tb_logs_dir = Path(\".\")\n",
    "tb_writer = SummaryWriter(log_dir='./tensorboard/fsl_albumen_224_effi2_m_2')\n",
    "\n",
    "\n",
    "best_state = few_shot_classifier.state_dict()\n",
    "if resum == True : \n",
    "    fsl_checkpoint = torch.load(os.paht.join(model_save_path,'2E_model.pt'))\n",
    "    few_shot_classifier.load_state_dict(fsl_checkpoint[\"model_state_dict\"])\n",
    "    train_optimizer.load_state_dict(fsl_checkpoint['optimizer_state_dict'])\n",
    "    start_e = fsl_checkpoint[\"epoch\"]\n",
    "    \n",
    "best_validation_accuracy = 0.0\n",
    "for epoch in range(start_e, n_epochs):\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    average_loss = training_epoch(few_shot_classifier, train_loader, train_optimizer)\n",
    "    validation_accuracy = evaluate(\n",
    "        few_shot_classifier, val_loader, device=args.DEVICE, tqdm_prefix=\"Validation\"\n",
    "    )\n",
    "\n",
    "    if validation_accuracy > best_validation_accuracy:\n",
    "        best_validation_accuracy = validation_accuracy\n",
    "        print(\"Ding ding ding! We found a new best model!\")\n",
    "        best_e = epoch\n",
    "        torch.save({\n",
    "                \"epoch\" : epoch,\n",
    "                \"model_state_dict\" : best_state,\n",
    "                \"optimizer_state_dict\" : train_optimizer.state_dict()\n",
    "            }, os.path.join(model_save_path, str(epoch)+'E_model.pt'))\n",
    "    \n",
    "\n",
    "    tb_writer.add_scalar(\"Train/loss\", average_loss, epoch)\n",
    "    tb_writer.add_scalar(\"Val/acc\", validation_accuracy, epoch)\n",
    "\n",
    "    # Warn the scheduler that we did an epoch\n",
    "    # so it knows when to decrease the learning rate\n",
    "    train_scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d92fc2",
   "metadata": {},
   "source": [
    "# Classical Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea44daf",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e622725",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import random\n",
    "from statistics import mean\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "import timm\n",
    "import os\n",
    "\n",
    "from easyfsl.methods.utils import evaluate\n",
    "from easydict import EasyDict\n",
    "\n",
    "args = EasyDict({'n_way' : 4, \n",
    "                 'n_shot' : 3, \n",
    "                 'n_query' : 6, \n",
    "                 'n_workers' : 6, \n",
    "                 'batch_size' : 32,\n",
    "                 'n_validation_tasks' :200,\n",
    "                 'DEVICE' : \"cuda\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1faba764",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6d543fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from easyfsl.datasets import CUSTOM\n",
    "from easyfsl.samplers import TaskSampler\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "train_set = CUSTOM(split=\"data/fsl_train\", image_size=224, training=True)\n",
    "train_loader = DataLoader(\n",
    "    train_set,\n",
    "    batch_size=args.batch_size,\n",
    "    num_workers=args.n_workers,\n",
    "    pin_memory=True,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "\n",
    "val_set = CUSTOM(split=\"data/fsl_valid\", image_size=224, training=True)\n",
    "\n",
    "val_sampler = TaskSampler(\n",
    "    val_set, \n",
    "    n_way=args.n_way, \n",
    "    n_shot=args.n_shot, \n",
    "    n_query=args.n_query, \n",
    "    n_tasks=args.n_validation_tasks\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_set,\n",
    "    batch_sampler=val_sampler,\n",
    "    num_workers=args.n_workers,\n",
    "    pin_memory=True,\n",
    "    collate_fn=val_sampler.episodic_collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816f93b2",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff8915fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from easyfsl.methods import PrototypicalNetworks, FewShotClassifier, TIM, RelationNetworks\n",
    "\n",
    "class CNN(nn.Module) :\n",
    "    def __init__(self, name='efficientnetv2_rw_m', num_classes=0)  :\n",
    "        super(CNN, self).__init__()\n",
    "        self.model = timm.create_model(name, pretrained=True, num_classes=num_classes)\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.flatten = nn.Flatten(1)\n",
    "        \n",
    "        self.use_fc = True\n",
    "        \n",
    "    def forward(self, x) :\n",
    "\n",
    "        if self.use_fc:\n",
    "            x = self.model(x)\n",
    "\n",
    "        else :\n",
    "            x = self.model.forward_features(x)\n",
    "            x = self.pool(x)\n",
    "            x = self.flatten(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def set_use_fc(self, x) :\n",
    "        self.use_fc = x\n",
    "        \n",
    "model = CNN(num_classes=len(set(train_set.get_labels()))).to(args.DEVICE)\n",
    "few_shot_classifier = PrototypicalNetworks(model).to(args.DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54d8a45",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e64d335",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import SGD, Optimizer, AdamW, Adam\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "n_epochs = 20\n",
    "scheduler_milestones = [3, 6]\n",
    "scheduler_gamma = 0.1\n",
    "learning_rate = 1e-3\n",
    "tb_logs_dir = './tensorboard/FSL_Classical_album_effi2_m'\n",
    "\n",
    "train_optimizer = Adam(\n",
    "    few_shot_classifier.parameters(), lr=learning_rate, weight_decay=5e-4\n",
    ")\n",
    "\n",
    "\n",
    "train_scheduler = MultiStepLR(\n",
    "    train_optimizer,\n",
    "    milestones=scheduler_milestones,\n",
    "    gamma=scheduler_gamma,\n",
    ")\n",
    "\n",
    "tb_writer = SummaryWriter(log_dir=tb_logs_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9de962c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_epoch(model_: nn.Module, data_loader: DataLoader, optimizer: Optimizer):\n",
    "    all_loss = []\n",
    "    model_.train()\n",
    "    with tqdm(data_loader, total=len(data_loader), desc=\"Training\") as tqdm_train:\n",
    "        for images, labels in tqdm_train:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss = criterion(model_(images.to(args.DEVICE)), labels.to(args.DEVICE))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            all_loss.append(loss.item())\n",
    "\n",
    "            tqdm_train.set_postfix(loss=mean(all_loss))\n",
    "\n",
    "    return mean(all_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff1aef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████| 450/450 [03:55<00:00,  1.91it/s, loss=2.43]\n",
      "Validation: 100%|█████████████████████████████████████████████████████| 200/200 [00:32<00:00,  6.16it/s, accuracy=0.63]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ding ding ding! We found a new best model!\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████| 450/450 [03:49<00:00,  1.96it/s, loss=2.12]\n",
      "Validation: 100%|████████████████████████████████████████████████████| 200/200 [00:32<00:00,  6.19it/s, accuracy=0.633]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ding ding ding! We found a new best model!\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████| 450/450 [03:50<00:00,  1.95it/s, loss=2.05]\n",
      "Validation: 100%|████████████████████████████████████████████████████| 200/200 [00:32<00:00,  6.07it/s, accuracy=0.644]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ding ding ding! We found a new best model!\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████| 450/450 [03:54<00:00,  1.92it/s, loss=1.6]\n",
      "Validation: 100%|█████████████████████████████████████████████████████| 200/200 [00:33<00:00,  6.02it/s, accuracy=0.69]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ding ding ding! We found a new best model!\n",
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████| 450/450 [03:53<00:00,  1.93it/s, loss=1.39]\n",
      "Validation: 100%|████████████████████████████████████████████████████| 200/200 [00:33<00:00,  6.00it/s, accuracy=0.634]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████| 450/450 [03:53<00:00,  1.93it/s, loss=1.24]\n",
      "Validation: 100%|████████████████████████████████████████████████████| 200/200 [00:32<00:00,  6.12it/s, accuracy=0.667]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████| 450/450 [03:53<00:00,  1.93it/s, loss=1.02]\n",
      "Validation: 100%|████████████████████████████████████████████████████| 200/200 [00:33<00:00,  6.02it/s, accuracy=0.665]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  54%|███████████████████████████████                           | 241/450 [02:09<01:41,  2.05it/s, loss=0.957]"
     ]
    }
   ],
   "source": [
    "from easyfsl.methods.utils import evaluate\n",
    "\n",
    "\n",
    "# best_state = model.state_dict()\n",
    "best_validation_accuracy = 0.0\n",
    "validation_frequency = 10\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    average_loss = training_epoch(model, train_loader, train_optimizer)\n",
    "\n",
    "#     if epoch % validation_frequency == validation_frequency - 1:\n",
    "\n",
    "        # We use this very convenient method from EasyFSL's ResNet to specify\n",
    "        # that the model shouldn't use its last fully connected layer during validation.\n",
    "    model.set_use_fc(False)\n",
    "    validation_accuracy = evaluate(\n",
    "        few_shot_classifier, val_loader, device=args.DEVICE, tqdm_prefix=\"Validation\"\n",
    "    )\n",
    "    model.set_use_fc(True)\n",
    "\n",
    "    if validation_accuracy > best_validation_accuracy:\n",
    "        best_validation_accuracy = validation_accuracy\n",
    "        best_state = model.state_dict()\n",
    "        print(\"Ding ding ding! We found a new best model!\")\n",
    "\n",
    "    tb_writer.add_scalar(\"Val/acc\", validation_accuracy, epoch)\n",
    "\n",
    "    tb_writer.add_scalar(\"Train/loss\", average_loss, epoch)\n",
    "\n",
    "    # Warn the scheduler that we did an epoch\n",
    "    # so it knows when to decrease the learning rate\n",
    "    train_scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e514814",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
