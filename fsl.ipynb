{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86523752",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f985e910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>img_path</th>\n",
       "      <th>overview</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_00000</td>\n",
       "      <td>./image/train/TRAIN_00000.jpg</td>\n",
       "      <td>소안항은 조용한 섬으로 인근해안이 청정해역으로 일찍이 김 양식을 해서 높은 소득을 ...</td>\n",
       "      <td>자연</td>\n",
       "      <td>자연관광지</td>\n",
       "      <td>항구/포구</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_00001</td>\n",
       "      <td>./image/train/TRAIN_00001.jpg</td>\n",
       "      <td>경기도 이천시 모가면에 있는 골프장으로 대중제 18홀이다. 회원제로 개장을 했다가 ...</td>\n",
       "      <td>레포츠</td>\n",
       "      <td>육상 레포츠</td>\n",
       "      <td>골프</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_00002</td>\n",
       "      <td>./image/train/TRAIN_00002.jpg</td>\n",
       "      <td>금오산성숯불갈비는 한우고기만을 전문적으로 취급하고 사용하는 부식 자재 또한 유기농법...</td>\n",
       "      <td>음식</td>\n",
       "      <td>음식점</td>\n",
       "      <td>한식</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_00003</td>\n",
       "      <td>./image/train/TRAIN_00003.jpg</td>\n",
       "      <td>철판 위에서 요리하는 안동찜닭을 맛볼 수 있는 곳이다. 경상북도 안동시에 있는 한식...</td>\n",
       "      <td>음식</td>\n",
       "      <td>음식점</td>\n",
       "      <td>한식</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_00004</td>\n",
       "      <td>./image/train/TRAIN_00004.jpg</td>\n",
       "      <td>※ 영업시간 10:30 ~ 20:30\\n\\n3대에 걸쳐 아귀만을 전문으로 취급하는 ...</td>\n",
       "      <td>음식</td>\n",
       "      <td>음식점</td>\n",
       "      <td>한식</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27345</th>\n",
       "      <td>aug_1_TRAIN_16367</td>\n",
       "      <td>./image/train\\aug_1_TRAIN_16367.jpg</td>\n",
       "      <td>남원 목공예사업협동조합 판매장 수십년간 식상과 목기를 만들어온 장인들이 현대화시설의...</td>\n",
       "      <td>쇼핑</td>\n",
       "      <td>쇼핑</td>\n",
       "      <td>특산물판매점</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27346</th>\n",
       "      <td>aug_2_TRAIN_16367</td>\n",
       "      <td>./image/train\\aug_2_TRAIN_16367.jpg</td>\n",
       "      <td>남원 목공예사업협동조합 판매장 수십년간 식상과 목기를 만들어온 장인들이 현대화시설의...</td>\n",
       "      <td>쇼핑</td>\n",
       "      <td>쇼핑</td>\n",
       "      <td>특산물판매점</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27347</th>\n",
       "      <td>aug_0_TRAIN_16556</td>\n",
       "      <td>./image/train\\aug_0_TRAIN_16556.jpg</td>\n",
       "      <td>지하1층,지상3층의 붉은 별돌 건물로 지하 1층에는 가든이 들어있고, 지상 1층에는...</td>\n",
       "      <td>쇼핑</td>\n",
       "      <td>쇼핑</td>\n",
       "      <td>특산물판매점</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27348</th>\n",
       "      <td>aug_1_TRAIN_16556</td>\n",
       "      <td>./image/train\\aug_1_TRAIN_16556.jpg</td>\n",
       "      <td>지하1층,지상3층의 붉은 별돌 건물로 지하 1층에는 가든이 들어있고, 지상 1층에는...</td>\n",
       "      <td>쇼핑</td>\n",
       "      <td>쇼핑</td>\n",
       "      <td>특산물판매점</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27349</th>\n",
       "      <td>aug_2_TRAIN_16556</td>\n",
       "      <td>./image/train\\aug_2_TRAIN_16556.jpg</td>\n",
       "      <td>지하1층,지상3층의 붉은 별돌 건물로 지하 1층에는 가든이 들어있고, 지상 1층에는...</td>\n",
       "      <td>쇼핑</td>\n",
       "      <td>쇼핑</td>\n",
       "      <td>특산물판매점</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27350 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                             img_path  \\\n",
       "0            TRAIN_00000        ./image/train/TRAIN_00000.jpg   \n",
       "1            TRAIN_00001        ./image/train/TRAIN_00001.jpg   \n",
       "2            TRAIN_00002        ./image/train/TRAIN_00002.jpg   \n",
       "3            TRAIN_00003        ./image/train/TRAIN_00003.jpg   \n",
       "4            TRAIN_00004        ./image/train/TRAIN_00004.jpg   \n",
       "...                  ...                                  ...   \n",
       "27345  aug_1_TRAIN_16367  ./image/train\\aug_1_TRAIN_16367.jpg   \n",
       "27346  aug_2_TRAIN_16367  ./image/train\\aug_2_TRAIN_16367.jpg   \n",
       "27347  aug_0_TRAIN_16556  ./image/train\\aug_0_TRAIN_16556.jpg   \n",
       "27348  aug_1_TRAIN_16556  ./image/train\\aug_1_TRAIN_16556.jpg   \n",
       "27349  aug_2_TRAIN_16556  ./image/train\\aug_2_TRAIN_16556.jpg   \n",
       "\n",
       "                                                overview cat1    cat2    cat3  \n",
       "0      소안항은 조용한 섬으로 인근해안이 청정해역으로 일찍이 김 양식을 해서 높은 소득을 ...   자연   자연관광지   항구/포구  \n",
       "1      경기도 이천시 모가면에 있는 골프장으로 대중제 18홀이다. 회원제로 개장을 했다가 ...  레포츠  육상 레포츠      골프  \n",
       "2      금오산성숯불갈비는 한우고기만을 전문적으로 취급하고 사용하는 부식 자재 또한 유기농법...   음식     음식점      한식  \n",
       "3      철판 위에서 요리하는 안동찜닭을 맛볼 수 있는 곳이다. 경상북도 안동시에 있는 한식...   음식     음식점      한식  \n",
       "4      ※ 영업시간 10:30 ~ 20:30\\n\\n3대에 걸쳐 아귀만을 전문으로 취급하는 ...   음식     음식점      한식  \n",
       "...                                                  ...  ...     ...     ...  \n",
       "27345  남원 목공예사업협동조합 판매장 수십년간 식상과 목기를 만들어온 장인들이 현대화시설의...   쇼핑      쇼핑  특산물판매점  \n",
       "27346  남원 목공예사업협동조합 판매장 수십년간 식상과 목기를 만들어온 장인들이 현대화시설의...   쇼핑      쇼핑  특산물판매점  \n",
       "27347  지하1층,지상3층의 붉은 별돌 건물로 지하 1층에는 가든이 들어있고, 지상 1층에는...   쇼핑      쇼핑  특산물판매점  \n",
       "27348  지하1층,지상3층의 붉은 별돌 건물로 지하 1층에는 가든이 들어있고, 지상 1층에는...   쇼핑      쇼핑  특산물판매점  \n",
       "27349  지하1층,지상3층의 붉은 별돌 건물로 지하 1층에는 가든이 들어있고, 지상 1층에는...   쇼핑      쇼핑  특산물판매점  \n",
       "\n",
       "[27350 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/aug_train.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6309ef52",
   "metadata": {},
   "source": [
    "# label 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe05725d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>자연</td>\n",
       "      <td>자연관광지</td>\n",
       "      <td>항구/포구</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>자연</td>\n",
       "      <td>자연관광지</td>\n",
       "      <td>섬</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>자연</td>\n",
       "      <td>자연관광지</td>\n",
       "      <td>자연휴양림</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>자연</td>\n",
       "      <td>자연관광지</td>\n",
       "      <td>해수욕장</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>자연</td>\n",
       "      <td>자연관광지</td>\n",
       "      <td>산</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>쇼핑</td>\n",
       "      <td>쇼핑</td>\n",
       "      <td>상설시장</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>쇼핑</td>\n",
       "      <td>쇼핑</td>\n",
       "      <td>공예,공방</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>쇼핑</td>\n",
       "      <td>쇼핑</td>\n",
       "      <td>백화점</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>쇼핑</td>\n",
       "      <td>쇼핑</td>\n",
       "      <td>면세점</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>쇼핑</td>\n",
       "      <td>쇼핑</td>\n",
       "      <td>특산물판매점</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    cat1   cat2    cat3 count\n",
       "0     자연  자연관광지   항구/포구   134\n",
       "1     자연  자연관광지       섬   111\n",
       "2     자연  자연관광지   자연휴양림   118\n",
       "3     자연  자연관광지    해수욕장   207\n",
       "4     자연  자연관광지       산   239\n",
       "..   ...    ...     ...   ...\n",
       "123   쇼핑     쇼핑    상설시장   270\n",
       "124   쇼핑     쇼핑   공예,공방   164\n",
       "125   쇼핑     쇼핑     백화점   108\n",
       "126   쇼핑     쇼핑     면세점   108\n",
       "127   쇼핑     쇼핑  특산물판매점   148\n",
       "\n",
       "[128 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df = pd.DataFrame(columns=['cat1','cat2','cat3','count'])\n",
    "for n_cat1 in df['cat1'].unique() :\n",
    "    cat2 = df[df['cat1'] == n_cat1]['cat2'].unique()\n",
    "    for n_cat2 in cat2 :\n",
    "        cat3  = df[df['cat1'] == n_cat1][df['cat2'] == n_cat2]['cat3'].unique()\n",
    "        for n_cat3 in cat3 :\n",
    "            cnt = len(df[df['cat1'] == n_cat1][df['cat2'] == n_cat2][df['cat3'] == n_cat3])\n",
    "            n = pd.DataFrame([[n_cat1, n_cat2, n_cat3, cnt]], columns=['cat1', 'cat2', 'cat3', 'count'])\n",
    "            label_df = pd.concat([label_df, n], ignore_index=True)\n",
    "\n",
    "label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3ed826c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'항구/포구': 0,\n",
       " '섬': 1,\n",
       " '자연휴양림': 2,\n",
       " '해수욕장': 3,\n",
       " '산': 4,\n",
       " '수목원': 5,\n",
       " '강': 6,\n",
       " '자연생태관광지': 7,\n",
       " '계곡': 8,\n",
       " '폭포': 9,\n",
       " '국립공원': 10,\n",
       " '해안절경': 11,\n",
       " '호수': 12,\n",
       " '동굴': 13,\n",
       " '도립공원': 14,\n",
       " '군립공원': 15,\n",
       " '약수터': 16,\n",
       " '등대': 17,\n",
       " '희귀동.식물': 18,\n",
       " '기암괴석': 19,\n",
       " '골프': 20,\n",
       " '야영장,오토캠핑장': 21,\n",
       " '스키(보드) 렌탈샵': 22,\n",
       " '자동차경주': 23,\n",
       " '자전거하이킹': 24,\n",
       " '썰매장': 25,\n",
       " '승마': 26,\n",
       " '트래킹': 27,\n",
       " '수련시설': 28,\n",
       " '카지노': 29,\n",
       " '번지점프': 30,\n",
       " '카트': 31,\n",
       " 'MTB': 32,\n",
       " '스케이트': 33,\n",
       " '인라인(실내 인라인 포함)': 34,\n",
       " '사격장': 35,\n",
       " 'ATV': 36,\n",
       " '빙벽등반': 37,\n",
       " '스키/스노보드': 38,\n",
       " '복합 레포츠': 39,\n",
       " '요트': 40,\n",
       " '래프팅': 41,\n",
       " '민물낚시': 42,\n",
       " '바다낚시': 43,\n",
       " '수영': 44,\n",
       " '카약/카누': 45,\n",
       " '윈드서핑/제트스키': 46,\n",
       " '스노쿨링/스킨스쿠버다이빙': 47,\n",
       " '스카이다이빙': 48,\n",
       " '헹글라이딩/패러글라이딩': 49,\n",
       " '수상레포츠': 50,\n",
       " '한식': 51,\n",
       " '일식': 52,\n",
       " '바/까페': 53,\n",
       " '채식전문점': 54,\n",
       " '중식': 55,\n",
       " '서양식': 56,\n",
       " '패밀리레스토랑': 57,\n",
       " '클럽': 58,\n",
       " '일반축제': 59,\n",
       " '문화관광축제': 60,\n",
       " '유적지/사적지': 61,\n",
       " '성': 62,\n",
       " '안보관광': 63,\n",
       " '사찰': 64,\n",
       " '종교성지': 65,\n",
       " '고택': 66,\n",
       " '고궁': 67,\n",
       " '민속마을': 68,\n",
       " '문': 69,\n",
       " '생가': 70,\n",
       " '전시관': 71,\n",
       " '미술관/화랑': 72,\n",
       " '박물관': 73,\n",
       " '도서관': 74,\n",
       " '공연장': 75,\n",
       " '기념관': 76,\n",
       " '문화전수시설': 77,\n",
       " '문화원': 78,\n",
       " '외국문화원': 79,\n",
       " '대형서점': 80,\n",
       " '영화관': 81,\n",
       " '학교': 82,\n",
       " '컨벤션센터': 83,\n",
       " '관광단지': 84,\n",
       " '공원': 85,\n",
       " '유원지': 86,\n",
       " '온천/욕장/스파': 87,\n",
       " '테마공원': 88,\n",
       " '유람선/잠수함관광': 89,\n",
       " '이색찜질방': 90,\n",
       " '헬스투어': 91,\n",
       " '컨벤션': 92,\n",
       " '박람회': 93,\n",
       " '기타행사': 94,\n",
       " '전통공연': 95,\n",
       " '대중콘서트': 96,\n",
       " '연극': 97,\n",
       " '뮤지컬': 98,\n",
       " '클래식음악회': 99,\n",
       " '이색거리': 100,\n",
       " '농.산.어촌 체험': 101,\n",
       " '이색체험': 102,\n",
       " '기념탑/기념비/전망대': 103,\n",
       " '유명건물': 104,\n",
       " '동상': 105,\n",
       " '다리/대교': 106,\n",
       " '분수': 107,\n",
       " '터널': 108,\n",
       " '기타': 109,\n",
       " '식음료': 110,\n",
       " '발전소': 111,\n",
       " '모텔': 112,\n",
       " '한옥스테이': 113,\n",
       " '펜션': 114,\n",
       " '게스트하우스': 115,\n",
       " '홈스테이': 116,\n",
       " '콘도미니엄': 117,\n",
       " '민박': 118,\n",
       " '유스호스텔': 119,\n",
       " '서비스드레지던스': 120,\n",
       " '전문상가': 121,\n",
       " '5일장': 122,\n",
       " '상설시장': 123,\n",
       " '공예,공방': 124,\n",
       " '백화점': 125,\n",
       " '면세점': 126,\n",
       " '특산물판매점': 127}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_encoder = {v : i for i, v in enumerate(label_df.loc[:, 'cat3'].values)}\n",
    "cat_encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503b8382",
   "metadata": {},
   "source": [
    "# FSL에 학습 규격에 맞춰서 이미지 이동"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56ebca3",
   "metadata": {},
   "source": [
    "### 경로 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91e6bf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = './data/fsl_img_train'\n",
    "os.makedirs(root_path, exist_ok=True)\n",
    "\n",
    "for i, label_name in enumerate(label_df['cat3'].values) :\n",
    "    fold_path = os.path.join(root_path, str(i))#label_name)\n",
    "    os.makedirs(fold_path, exist_ok=True)\n",
    "\n",
    "root_path = './data/fsl_img_valid'\n",
    "os.makedirs(root_path, exist_ok=True)\n",
    "\n",
    "for i, label_name in enumerate(label_df['cat3'].values) :\n",
    "    fold_path = os.path.join(root_path, str(i))#label_name)\n",
    "    os.makedirs(fold_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284ee505",
   "metadata": {},
   "source": [
    "## 데이터 쪼개기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e54b434",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "kfold = StratifiedKFold(n_splits=4, random_state=99, shuffle=True)\n",
    "img_set = df['img_path']\n",
    "label_set = df['cat3']\n",
    "\n",
    "for train_ind, valid_ind in kfold.split(img_set, label_set) :\n",
    "    train_df = df.iloc[train_ind]\n",
    "    valid_df = df.iloc[valid_ind]\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdebe23",
   "metadata": {},
   "source": [
    "### 이미지 이동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f969a56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 20512/20512 [00:23<00:00, 879.99it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 6838/6838 [00:09<00:00, 737.91it/s]\n"
     ]
    }
   ],
   "source": [
    "# df.iloc[0]\n",
    "source_root_path = './data'\n",
    "dest_root_path = './data/fsl_img_train'\n",
    "\n",
    "for i in tqdm(range(len(train_df))):\n",
    "    img_path = os.path.join(source_root_path, train_df.iloc[i]['img_path'])\n",
    "    label = cat_encoder[train_df.iloc[i]['cat3']] #df.iloc[i]['cat3'] \n",
    "    img_name = train_df.iloc[i]['id']\n",
    "    dest_path = os.path.join(dest_root_path, str(label), img_name+'.jpg')\n",
    "    \n",
    "    # copy\n",
    "    shutil.copyfile(img_path, dest_path)\n",
    "\n",
    "source_root_path = './data'\n",
    "dest_root_path = './data/fsl_img_valid'\n",
    "\n",
    "for i in tqdm(range(len(valid_df))):\n",
    "    img_path = os.path.join(source_root_path, valid_df.iloc[i]['img_path'])\n",
    "    label = cat_encoder[valid_df.iloc[i]['cat3']] #df.iloc[i]['cat3'] \n",
    "    img_name = valid_df.iloc[i]['id']\n",
    "    dest_path = os.path.join(dest_root_path, str(label), img_name+'.jpg')\n",
    "    \n",
    "    # copy\n",
    "    shutil.copyfile(img_path, dest_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e925b32",
   "metadata": {},
   "source": [
    "# FSL에 이용하는 json 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b227727",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from glob import glob\n",
    "from collections import defaultdict\n",
    "import json\n",
    "\n",
    "fsl_t = defaultdict(list)\n",
    "fsl_v = defaultdict(list)\n",
    "\n",
    "# vaild_pick = random.sample([i for i in range(128)], 26)\n",
    "\n",
    "t_path = './data/fsl_img_train/*'\n",
    "v_path = './data/fsl_img_valid/*'\n",
    "\n",
    "t_label_list = glob(t_path)\n",
    "t_label_list.sort(key=lambda x: int(x.split('\\\\')[-1]))\n",
    "\n",
    "v_label_list = glob(v_path)\n",
    "v_label_list.sort(key=lambda x: int(x.split('\\\\')[-1].split('.')[0]))\n",
    "\n",
    "\n",
    "\n",
    "for idx, label in enumerate(t_label_list) :  \n",
    "    fsl_t['class_roots'].append(label)\n",
    "    fsl_t['class_names'].append(label.split('\\\\')[-1])\n",
    "\n",
    "\n",
    "for idx, label in enumerate(v_label_list) :  \n",
    "    fsl_v['class_roots'].append(label)\n",
    "    fsl_v['class_names'].append(label.split('\\\\')[-1])\n",
    "\n",
    "    \n",
    "with open('./data/kfold_fsl_train.json', 'w') as f:\n",
    "    json.dump(fsl_t, f, indent=2)\n",
    "    \n",
    "with open('./data/kfold_fsl_valid.json', 'w') as f:\n",
    "    json.dump(fsl_v, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2855ba2",
   "metadata": {},
   "source": [
    "# FSL configuration 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d471a3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import random\n",
    "from statistics import mean\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "import timm\n",
    "import os\n",
    "\n",
    "from easyfsl.methods.utils import evaluate\n",
    "from easydict import EasyDict\n",
    "\n",
    "args = EasyDict({'n_way' : 4, \n",
    "                 'n_shot' : 3, \n",
    "                 'n_query' : 6, \n",
    "                 'n_workers' : 6, \n",
    "                 'n_epochs' : 30,\n",
    "                 'BATCH_SIZE' : 32, \n",
    "                 'RESIZE' : 300,\n",
    "                 'TRAIN_PATH' : 'data/kfold_fsl_train',\n",
    "                 'VALID_PATH' : 'data/kfold_fsl_valid',\n",
    "                 'n_validation_tasks' :200,\n",
    "                 'n_tasks_per_epoch' : 300,\n",
    "                 'MODEL_NAME' : 'efficientnet_b3',\n",
    "                 'MODEL_SAVE_PATH' : './ckpt/fsl/albumen_300_effib3',\n",
    "                 'DEVICE' : \"cuda\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03f8f7b",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09e36553",
   "metadata": {},
   "outputs": [],
   "source": [
    "from easyfsl.datasets import CUB, CUSTOM\n",
    "from easyfsl.samplers import TaskSampler\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "train_set = CUSTOM(split=args.TRAIN_PATH, image_size=args.RESIZE ,training=True)\n",
    "val_set = CUSTOM(split=args.VALID_PATH, image_size=args.RESIZE, training=False)\n",
    "\n",
    "train_sampler = TaskSampler(\n",
    "    train_set, \n",
    "    n_way=args.n_way, \n",
    "    n_shot=args.n_shot, \n",
    "    n_query=args.n_query, \n",
    "    n_tasks=args.n_tasks_per_epoch\n",
    ")\n",
    "val_sampler = TaskSampler(\n",
    "    val_set, \n",
    "    n_way=args.n_way, \n",
    "    n_shot=args.n_shot, \n",
    "    n_query=args.n_query, \n",
    "    n_tasks=args.n_validation_tasks\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_set,\n",
    "    batch_sampler=train_sampler,\n",
    "    num_workers=args.n_workers,\n",
    "    pin_memory=True,\n",
    "    collate_fn=train_sampler.episodic_collate_fn,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_set,\n",
    "    batch_sampler=val_sampler,\n",
    "    num_workers=args.n_workers,\n",
    "    pin_memory=True,\n",
    "    collate_fn=val_sampler.episodic_collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ef1182",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e62fc52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module) :\n",
    "    def __init__(self, model_name='efficientnetv2_rw_m', num_classes=0)  :\n",
    "        super(CNN, self).__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=True, num_classes=num_classes, global_pool='')\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.flatten = nn.Flatten(1)\n",
    "        \n",
    "    def forward(self, x) :\n",
    "        x = self.model.forward_features(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.flatten(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25e636fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from easyfsl.methods import PrototypicalNetworks, FewShotClassifier, TIM, RelationNetworks\n",
    "\n",
    "convolutional_network = CNN(model_name=args.MODEL_NAME).to(args.DEVICE)\n",
    "few_shot_classifier = PrototypicalNetworks(convolutional_network).to(args.DEVICE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263d657b",
   "metadata": {},
   "source": [
    "# Episodic Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08fdd96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import SGD, Optimizer, AdamW, Adam\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "scheduler_milestones = [3, 6]\n",
    "scheduler_gamma = 0.1\n",
    "learning_rate = 1e-3\n",
    "\n",
    "\n",
    "train_optimizer = Adam(\n",
    "    few_shot_classifier.parameters(), lr=learning_rate, weight_decay=5e-4)#,  momentum=0.9)\n",
    "\n",
    "\n",
    "train_scheduler = MultiStepLR(\n",
    "    train_optimizer,\n",
    "    milestones=scheduler_milestones,\n",
    "    gamma=scheduler_gamma,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85a926b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_epoch(\n",
    "    model: FewShotClassifier, data_loader: DataLoader, optimizer: Optimizer\n",
    "):\n",
    "    all_loss = []\n",
    "    model.train()\n",
    "    with tqdm(\n",
    "        enumerate(data_loader), total=len(data_loader), desc=\"Training\"\n",
    "    ) as tqdm_train:\n",
    "        for episode_index, (\n",
    "            support_images,\n",
    "            support_labels,\n",
    "            query_images,\n",
    "            query_labels,\n",
    "            _,\n",
    "        ) in tqdm_train:\n",
    "            optimizer.zero_grad()\n",
    "            model.process_support_set(\n",
    "                support_images.to(args.DEVICE), support_labels.to(args.DEVICE)\n",
    "            )\n",
    "            classification_scores = model(query_images.to(args.DEVICE))\n",
    "\n",
    "            loss = criterion(classification_scores, query_labels.to(args.DEVICE))\n",
    "#             loss.requires_grad_(True)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            all_loss.append(loss.item())\n",
    "\n",
    "            tqdm_train.set_postfix(loss=mean(all_loss))\n",
    "\n",
    "    return mean(all_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17911b27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████| 300/300 [02:32<00:00,  1.97it/s, loss=0.866]\n",
      "Validation: 100%|███████████████████████████████████████████████████████| 200/200 [00:26<00:00,  7.62it/s, accuracy=0.61]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ding ding ding! We found a new best model!\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████| 300/300 [02:29<00:00,  2.01it/s, loss=0.881]\n",
      "Validation: 100%|██████████████████████████████████████████████████████| 200/200 [00:26<00:00,  7.69it/s, accuracy=0.613]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ding ding ding! We found a new best model!\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████| 300/300 [02:29<00:00,  2.01it/s, loss=0.819]\n",
      "Validation: 100%|██████████████████████████████████████████████████████| 200/200 [00:26<00:00,  7.69it/s, accuracy=0.617]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ding ding ding! We found a new best model!\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████████████████████████████████████████████████████████| 300/300 [02:28<00:00,  2.02it/s, loss=0.72]\n",
      "Validation: 100%|██████████████████████████████████████████████████████| 200/200 [00:25<00:00,  7.73it/s, accuracy=0.718]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ding ding ding! We found a new best model!\n",
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████| 300/300 [02:28<00:00,  2.02it/s, loss=0.635]\n",
      "Validation: 100%|██████████████████████████████████████████████████████| 200/200 [00:26<00:00,  7.68it/s, accuracy=0.724]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ding ding ding! We found a new best model!\n",
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████| 300/300 [02:28<00:00,  2.02it/s, loss=0.567]\n",
      "Validation: 100%|██████████████████████████████████████████████████████| 200/200 [00:26<00:00,  7.68it/s, accuracy=0.753]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ding ding ding! We found a new best model!\n",
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████| 300/300 [02:28<00:00,  2.02it/s, loss=0.541]\n",
      "Validation: 100%|██████████████████████████████████████████████████████| 200/200 [00:26<00:00,  7.68it/s, accuracy=0.745]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████| 300/300 [02:28<00:00,  2.02it/s, loss=0.533]\n",
      "Validation: 100%|██████████████████████████████████████████████████████| 200/200 [00:26<00:00,  7.67it/s, accuracy=0.765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ding ding ding! We found a new best model!\n",
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████| 300/300 [02:28<00:00,  2.02it/s, loss=0.527]\n",
      "Validation: 100%|██████████████████████████████████████████████████████| 200/200 [00:26<00:00,  7.68it/s, accuracy=0.756]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████| 300/300 [02:28<00:00,  2.02it/s, loss=0.519]\n",
      "Validation: 100%|██████████████████████████████████████████████████████| 200/200 [00:26<00:00,  7.67it/s, accuracy=0.764]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████| 300/300 [02:28<00:00,  2.02it/s, loss=0.497]\n",
      "Validation: 100%|██████████████████████████████████████████████████████| 200/200 [00:26<00:00,  7.66it/s, accuracy=0.768]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ding ding ding! We found a new best model!\n",
      "Epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████| 300/300 [02:28<00:00,  2.02it/s, loss=0.507]\n",
      "Validation: 100%|██████████████████████████████████████████████████████| 200/200 [00:26<00:00,  7.67it/s, accuracy=0.764]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████| 300/300 [02:28<00:00,  2.02it/s, loss=0.505]\n",
      "Validation: 100%|██████████████████████████████████████████████████████| 200/200 [00:26<00:00,  7.66it/s, accuracy=0.767]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████████████████████████████████████████████████████████| 300/300 [02:28<00:00,  2.02it/s, loss=0.46]\n",
      "Validation: 100%|██████████████████████████████████████████████████████| 200/200 [00:26<00:00,  7.69it/s, accuracy=0.756]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████| 300/300 [02:28<00:00,  2.02it/s, loss=0.491]\n",
      "Validation: 100%|██████████████████████████████████████████████████████| 200/200 [00:26<00:00,  7.68it/s, accuracy=0.782]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ding ding ding! We found a new best model!\n",
      "Epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████| 300/300 [02:28<00:00,  2.02it/s, loss=0.474]\n",
      "Validation: 100%|███████████████████████████████████████████████████████| 200/200 [00:26<00:00,  7.69it/s, accuracy=0.77]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████████████████████████████████████████████████████████| 300/300 [02:28<00:00,  2.02it/s, loss=0.48]\n",
      "Validation: 100%|██████████████████████████████████████████████████████| 200/200 [00:26<00:00,  7.67it/s, accuracy=0.772]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████| 300/300 [02:28<00:00,  2.02it/s, loss=0.449]\n",
      "Validation: 100%|██████████████████████████████████████████████████████| 200/200 [00:26<00:00,  7.67it/s, accuracy=0.787]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ding ding ding! We found a new best model!\n",
      "Epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████| 300/300 [02:28<00:00,  2.02it/s, loss=0.473]\n",
      "Validation: 100%|███████████████████████████████████████████████████████| 200/200 [00:26<00:00,  7.67it/s, accuracy=0.78]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████| 300/300 [02:28<00:00,  2.02it/s, loss=0.461]\n",
      "Validation: 100%|██████████████████████████████████████████████████████| 200/200 [00:26<00:00,  7.68it/s, accuracy=0.772]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████| 300/300 [02:28<00:00,  2.02it/s, loss=0.461]\n",
      "Validation: 100%|██████████████████████████████████████████████████████| 200/200 [00:26<00:00,  7.68it/s, accuracy=0.763]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████| 300/300 [02:28<00:00,  2.02it/s, loss=0.426]\n",
      "Validation: 100%|██████████████████████████████████████████████████████| 200/200 [00:26<00:00,  7.68it/s, accuracy=0.759]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████| 300/300 [02:28<00:00,  2.02it/s, loss=0.474]\n",
      "Validation: 100%|██████████████████████████████████████████████████████| 200/200 [00:26<00:00,  7.67it/s, accuracy=0.767]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████| 300/300 [02:28<00:00,  2.02it/s, loss=0.442]\n",
      "Validation: 100%|██████████████████████████████████████████████████████| 200/200 [00:26<00:00,  7.68it/s, accuracy=0.789]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ding ding ding! We found a new best model!\n",
      "Epoch 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████| 300/300 [02:28<00:00,  2.02it/s, loss=0.461]\n",
      "Validation: 100%|██████████████████████████████████████████████████████| 200/200 [00:25<00:00,  7.69it/s, accuracy=0.776]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████| 300/300 [02:28<00:00,  2.02it/s, loss=0.393]\n",
      "Validation: 100%|██████████████████████████████████████████████████████| 200/200 [00:25<00:00,  7.71it/s, accuracy=0.795]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ding ding ding! We found a new best model!\n",
      "Epoch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████| 300/300 [02:28<00:00,  2.01it/s, loss=0.425]\n",
      "Validation: 100%|██████████████████████████████████████████████████████| 200/200 [00:26<00:00,  7.68it/s, accuracy=0.781]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████| 300/300 [02:28<00:00,  2.02it/s, loss=0.455]\n",
      "Validation: 100%|██████████████████████████████████████████████████████| 200/200 [00:26<00:00,  7.63it/s, accuracy=0.787]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████| 300/300 [02:28<00:00,  2.02it/s, loss=0.402]\n",
      "Validation: 100%|██████████████████████████████████████████████████████| 200/200 [00:25<00:00,  7.72it/s, accuracy=0.795]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████| 300/300 [02:28<00:00,  2.02it/s, loss=0.413]\n",
      "Validation: 100%|██████████████████████████████████████████████████████| 200/200 [00:25<00:00,  7.70it/s, accuracy=0.787]\n"
     ]
    }
   ],
   "source": [
    "from easyfsl.methods.utils import evaluate\n",
    "\n",
    "start_e = 0\n",
    "best_e = None\n",
    "resum = False\n",
    "model_save_path = './ckpt/fsl/epcisodic_albumen_300_effib3'\n",
    "os.makedirs(model_save_path, exist_ok=True)\n",
    "\n",
    "tb_logs_dir = Path(\".\")\n",
    "tb_writer = SummaryWriter(log_dir='./tensorboard/epcisodic_albumen_224_effib3')\n",
    "\n",
    "\n",
    "if resum == True : \n",
    "    fsl_checkpoint = torch.load(os.paht.join(model_save_path,'2E_model.pt'))\n",
    "    few_shot_classifier.load_state_dict(fsl_checkpoint[\"model_state_dict\"])\n",
    "    train_optimizer.load_state_dict(fsl_checkpoint['optimizer_state_dict'])\n",
    "    start_e = fsl_checkpoint[\"epoch\"]\n",
    "    \n",
    "best_validation_accuracy = 0.0\n",
    "for epoch in range(start_e, args.n_epochs):\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    average_loss = training_epoch(few_shot_classifier, train_loader, train_optimizer)\n",
    "    validation_accuracy = evaluate(\n",
    "        few_shot_classifier, val_loader, device=args.DEVICE, tqdm_prefix=\"Validation\"\n",
    "    )\n",
    "\n",
    "    if validation_accuracy > best_validation_accuracy:\n",
    "        best_validation_accuracy = validation_accuracy\n",
    "        print(\"Ding ding ding! We found a new best model!\")\n",
    "        best_e = epoch\n",
    "        torch.save({\n",
    "                \"epoch\" : epoch,\n",
    "                \"model_state_dict\" : few_shot_classifier.state_dict(),\n",
    "                \"optimizer_state_dict\" : train_optimizer.state_dict()\n",
    "            }, os.path.join(model_save_path, str(epoch)+'E_'+str(round(best_validation_accuracy, 4))+'_model.pt'))\n",
    "    \n",
    "\n",
    "    tb_writer.add_scalar(\"Train/loss\", average_loss, epoch)\n",
    "    tb_writer.add_scalar(\"Val/acc\", validation_accuracy, epoch)\n",
    "\n",
    "    # Warn the scheduler that we did an epoch\n",
    "    # so it knows when to decrease the learning rate\n",
    "    train_scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d92fc2",
   "metadata": {},
   "source": [
    "# Classical Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea44daf",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e622725",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import random\n",
    "from statistics import mean\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "import timm\n",
    "import os\n",
    "\n",
    "from easyfsl.methods.utils import evaluate\n",
    "from easydict import EasyDict\n",
    "\n",
    "args = EasyDict({'n_way' : 4, \n",
    "                 'n_shot' : 3, \n",
    "                 'n_query' : 6, \n",
    "                 'n_workers' : 6, \n",
    "                 'n_epochs' : 30,\n",
    "                 'BATCH_SIZE' : 32, \n",
    "                 'RESIZE' : 300,\n",
    "                 'TRAIN_PATH' : 'data/full_fsl_train',\n",
    "                 'VALID_PATH' : 'data/CUB_fsl_valid',\n",
    "                 'n_validation_tasks' :200,\n",
    "                 'MODEL_NAME' : 'efficientnet_b3',\n",
    "                 'MODEL_SAVE_PATH' : './ckpt/fsl/albumen_300_effib3',\n",
    "                 'DEVICE' : \"cuda\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1faba764",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6d543fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from easyfsl.datasets import CUSTOM\n",
    "from easyfsl.samplers import TaskSampler\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "train_set = CUSTOM(split=args.TRAIN_PATH, image_size=args.RESIZE, training=True)\n",
    "train_loader = DataLoader(\n",
    "    train_set,\n",
    "    batch_size=args.BATCH_SIZE,\n",
    "    num_workers=args.n_workers,\n",
    "    pin_memory=True,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "\n",
    "val_set = CUSTOM(split=args.VALID_PATH, image_size=args.RESIZE, training=True)\n",
    "\n",
    "val_sampler = TaskSampler(\n",
    "    val_set, \n",
    "    n_way=args.n_way, \n",
    "    n_shot=args.n_shot, \n",
    "    n_query=args.n_query, \n",
    "    n_tasks=args.n_validation_tasks\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_set,\n",
    "    batch_sampler=val_sampler,\n",
    "    num_workers=args.n_workers,\n",
    "    pin_memory=True,\n",
    "    collate_fn=val_sampler.episodic_collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816f93b2",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff8915fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes =  128\n"
     ]
    }
   ],
   "source": [
    "from easyfsl.methods import PrototypicalNetworks, FewShotClassifier, TIM, RelationNetworks\n",
    "\n",
    "class CNN(nn.Module) :\n",
    "    def __init__(self, model_name='efficientnet_b3', num_classes=0)  :\n",
    "        super(CNN, self).__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=True, num_classes=num_classes)\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.flatten = nn.Flatten(1)\n",
    "        \n",
    "        self.use_fc = True\n",
    "        \n",
    "    def forward(self, x) :\n",
    "\n",
    "        if self.use_fc:\n",
    "            x = self.model(x)\n",
    "\n",
    "        else :\n",
    "            x = self.model.forward_features(x)\n",
    "            x = self.pool(x)\n",
    "            x = self.flatten(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def set_use_fc(self, x) :\n",
    "        self.use_fc = x\n",
    "        \n",
    "model = CNN(model_name=args.MODEL_NAME, \n",
    "            num_classes=len(set(train_set.get_labels()))).to(args.DEVICE)\n",
    "print('num_classes = ',len(set(train_set.get_labels())))\n",
    "few_shot_classifier = PrototypicalNetworks(model).to(args.DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54d8a45",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e64d335",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import SGD, Optimizer, AdamW, Adam\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "scheduler_milestones = [3, 6]\n",
    "scheduler_gamma = 0.1\n",
    "learning_rate = 1e-3\n",
    "tb_logs_dir = './tensorboard/FSL_Classical_album_effib3'\n",
    "\n",
    "import os\n",
    "os.makedirs(args.MODEL_SAVE_PATH, exist_ok=True)\n",
    "\n",
    "train_optimizer = Adam(\n",
    "    few_shot_classifier.parameters(), lr=learning_rate, weight_decay=5e-4\n",
    ")\n",
    "\n",
    "\n",
    "train_scheduler = MultiStepLR(\n",
    "    train_optimizer,\n",
    "    milestones=scheduler_milestones,\n",
    "    gamma=scheduler_gamma,\n",
    ")\n",
    "\n",
    "tb_writer = SummaryWriter(log_dir=tb_logs_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9de962c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_epoch(model_: nn.Module, data_loader: DataLoader, optimizer: Optimizer):\n",
    "    all_loss = []\n",
    "    model_.train()\n",
    "    with tqdm(data_loader, total=len(data_loader), desc=\"Training\") as tqdm_train:\n",
    "        for images, labels in tqdm_train:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss = criterion(model_(images.to(args.DEVICE)), labels.to(args.DEVICE))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            all_loss.append(loss.item())\n",
    "\n",
    "            tqdm_train.set_postfix(loss=mean(all_loss))\n",
    "\n",
    "    return mean(all_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ff1aef0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████████████████████████████████████████████████████████| 543/543 [04:08<00:00,  2.19it/s, loss=2.51]\n",
      "Validation: 100%|███████████████████████████████████████████████████████| 200/200 [00:25<00:00,  7.96it/s, accuracy=0.54]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ding ding ding! We found a new best model!\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████████████████████████████████████████████████████████| 543/543 [04:00<00:00,  2.26it/s, loss=2.12]\n",
      "Validation: 100%|██████████████████████████████████████████████████████| 200/200 [00:25<00:00,  7.84it/s, accuracy=0.518]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████████████████████████████████████████████████████████| 543/543 [04:02<00:00,  2.24it/s, loss=2.04]\n",
      "Validation: 100%|██████████████████████████████████████████████████████| 200/200 [00:26<00:00,  7.54it/s, accuracy=0.471]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|█████████████████████████████████████████████████████████████| 543/543 [04:03<00:00,  2.23it/s, loss=1.56]\n",
      "Validation: 100%|██████████████████████████████████████████████████████| 200/200 [00:25<00:00,  7.81it/s, accuracy=0.512]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  33%|████████████████████▎                                        | 181/543 [01:30<03:00,  2.01it/s, loss=1.32]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(args\u001b[38;5;241m.\u001b[39mn_epochs):\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m     average_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_optimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m#     if epoch % validation_frequency == validation_frequency - 1:\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \n\u001b[0;32m     14\u001b[0m         \u001b[38;5;66;03m# We use this very convenient method from EasyFSL's ResNet to specify\u001b[39;00m\n\u001b[0;32m     15\u001b[0m         \u001b[38;5;66;03m# that the model shouldn't use its last fully connected layer during validation.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     model\u001b[38;5;241m.\u001b[39mset_use_fc(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36mtraining_epoch\u001b[1;34m(model_, data_loader, optimizer)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m tqdm_train:\n\u001b[0;32m      6\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m----> 8\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(model_(images\u001b[38;5;241m.\u001b[39mto(args\u001b[38;5;241m.\u001b[39mDEVICE)), \u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      9\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     10\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from easyfsl.methods.utils import evaluate\n",
    "\n",
    "\n",
    "# best_state = model.state_dict()\n",
    "best_validation_accuracy = 0.0\n",
    "validation_frequency = 10\n",
    "\n",
    "for epoch in range(args.n_epochs):\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    average_loss = training_epoch(model, train_loader, train_optimizer)\n",
    "\n",
    "#     if epoch % validation_frequency == validation_frequency - 1:\n",
    "\n",
    "        # We use this very convenient method from EasyFSL's ResNet to specify\n",
    "        # that the model shouldn't use its last fully connected layer during validation.\n",
    "    model.set_use_fc(False)\n",
    "    validation_accuracy = evaluate(\n",
    "        few_shot_classifier, val_loader, device=args.DEVICE, tqdm_prefix=\"Validation\"\n",
    "    )\n",
    "    model.set_use_fc(True)\n",
    "\n",
    "    if validation_accuracy > best_validation_accuracy:\n",
    "        best_validation_accuracy = validation_accuracy\n",
    "        best_state = model.state_dict()\n",
    "        print(\"Ding ding ding! We found a new best model!\")\n",
    "        best_e = epoch\n",
    "        torch.save({\n",
    "                \"epoch\" : epoch,\n",
    "                \"model_state_dict\" : best_state,\n",
    "                \"optimizer_state_dict\" : train_optimizer.state_dict()\n",
    "            }, os.path.join(args.MODEL_SAVE_PATH, str(epoch)+'E_'+str(round(best_validation_accuracy, 4))+'_model.pt'))\n",
    "        \n",
    "    tb_writer.add_scalar(\"Val/acc\", validation_accuracy, epoch)\n",
    "\n",
    "    tb_writer.add_scalar(\"Train/loss\", average_loss, epoch)\n",
    "\n",
    "    # Warn the scheduler that we did an epoch\n",
    "    # so it knows when to decrease the learning rate\n",
    "    train_scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e514814",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10e3e9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 7, 7, 9, 16]\n"
     ]
    }
   ],
   "source": [
    "a = [9,1,4,7,16,7]\n",
    "a.sort()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca280bff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
