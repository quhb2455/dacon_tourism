{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5a8d9429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2e4da4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/aug_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e66484b",
   "metadata": {},
   "source": [
    "# label 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "dec53a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>자연</td>\n",
       "      <td>자연관광지</td>\n",
       "      <td>항구/포구</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>자연</td>\n",
       "      <td>자연관광지</td>\n",
       "      <td>섬</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>자연</td>\n",
       "      <td>자연관광지</td>\n",
       "      <td>자연휴양림</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>자연</td>\n",
       "      <td>자연관광지</td>\n",
       "      <td>해수욕장</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>자연</td>\n",
       "      <td>자연관광지</td>\n",
       "      <td>산</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>쇼핑</td>\n",
       "      <td>쇼핑</td>\n",
       "      <td>상설시장</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>쇼핑</td>\n",
       "      <td>쇼핑</td>\n",
       "      <td>공예,공방</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>쇼핑</td>\n",
       "      <td>쇼핑</td>\n",
       "      <td>백화점</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>쇼핑</td>\n",
       "      <td>쇼핑</td>\n",
       "      <td>면세점</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>쇼핑</td>\n",
       "      <td>쇼핑</td>\n",
       "      <td>특산물판매점</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    cat1   cat2    cat3 count\n",
       "0     자연  자연관광지   항구/포구   134\n",
       "1     자연  자연관광지       섬   111\n",
       "2     자연  자연관광지   자연휴양림   118\n",
       "3     자연  자연관광지    해수욕장   207\n",
       "4     자연  자연관광지       산   239\n",
       "..   ...    ...     ...   ...\n",
       "123   쇼핑     쇼핑    상설시장   270\n",
       "124   쇼핑     쇼핑   공예,공방    41\n",
       "125   쇼핑     쇼핑     백화점    16\n",
       "126   쇼핑     쇼핑     면세점    18\n",
       "127   쇼핑     쇼핑  특산물판매점    37\n",
       "\n",
       "[128 rows x 4 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df = pd.DataFrame(columns=['cat1','cat2','cat3','count'])\n",
    "for n_cat1 in df['cat1'].unique() :\n",
    "    cat2 = df[df['cat1'] == n_cat1]['cat2'].unique()\n",
    "    for n_cat2 in cat2 :\n",
    "        cat3  = df[df['cat1'] == n_cat1][df['cat2'] == n_cat2]['cat3'].unique()\n",
    "        for n_cat3 in cat3 :\n",
    "            cnt = len(df[df['cat1'] == n_cat1][df['cat2'] == n_cat2][df['cat3'] == n_cat3])\n",
    "            n = pd.DataFrame([[n_cat1, n_cat2, n_cat3, cnt]], columns=['cat1', 'cat2', 'cat3', 'count'])\n",
    "            label_df = pd.concat([label_df, n], ignore_index=True)\n",
    "\n",
    "label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c28ceb29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'항구/포구': 0,\n",
       " '섬': 1,\n",
       " '자연휴양림': 2,\n",
       " '해수욕장': 3,\n",
       " '산': 4,\n",
       " '수목원': 5,\n",
       " '강': 6,\n",
       " '자연생태관광지': 7,\n",
       " '계곡': 8,\n",
       " '폭포': 9,\n",
       " '국립공원': 10,\n",
       " '해안절경': 11,\n",
       " '호수': 12,\n",
       " '동굴': 13,\n",
       " '도립공원': 14,\n",
       " '군립공원': 15,\n",
       " '약수터': 16,\n",
       " '등대': 17,\n",
       " '희귀동.식물': 18,\n",
       " '기암괴석': 19,\n",
       " '골프': 20,\n",
       " '야영장,오토캠핑장': 21,\n",
       " '스키(보드) 렌탈샵': 22,\n",
       " '자동차경주': 23,\n",
       " '자전거하이킹': 24,\n",
       " '썰매장': 25,\n",
       " '승마': 26,\n",
       " '트래킹': 27,\n",
       " '수련시설': 28,\n",
       " '카지노': 29,\n",
       " '번지점프': 30,\n",
       " '카트': 31,\n",
       " 'MTB': 32,\n",
       " '스케이트': 33,\n",
       " '인라인(실내 인라인 포함)': 34,\n",
       " '사격장': 35,\n",
       " 'ATV': 36,\n",
       " '빙벽등반': 37,\n",
       " '스키/스노보드': 38,\n",
       " '복합 레포츠': 39,\n",
       " '요트': 40,\n",
       " '래프팅': 41,\n",
       " '민물낚시': 42,\n",
       " '바다낚시': 43,\n",
       " '수영': 44,\n",
       " '카약/카누': 45,\n",
       " '윈드서핑/제트스키': 46,\n",
       " '스노쿨링/스킨스쿠버다이빙': 47,\n",
       " '스카이다이빙': 48,\n",
       " '헹글라이딩/패러글라이딩': 49,\n",
       " '수상레포츠': 50,\n",
       " '한식': 51,\n",
       " '일식': 52,\n",
       " '바/까페': 53,\n",
       " '채식전문점': 54,\n",
       " '중식': 55,\n",
       " '서양식': 56,\n",
       " '패밀리레스토랑': 57,\n",
       " '클럽': 58,\n",
       " '일반축제': 59,\n",
       " '문화관광축제': 60,\n",
       " '유적지/사적지': 61,\n",
       " '성': 62,\n",
       " '안보관광': 63,\n",
       " '사찰': 64,\n",
       " '종교성지': 65,\n",
       " '고택': 66,\n",
       " '고궁': 67,\n",
       " '민속마을': 68,\n",
       " '문': 69,\n",
       " '생가': 70,\n",
       " '전시관': 71,\n",
       " '미술관/화랑': 72,\n",
       " '박물관': 73,\n",
       " '도서관': 74,\n",
       " '공연장': 75,\n",
       " '기념관': 76,\n",
       " '문화전수시설': 77,\n",
       " '문화원': 78,\n",
       " '외국문화원': 79,\n",
       " '대형서점': 80,\n",
       " '영화관': 81,\n",
       " '학교': 82,\n",
       " '컨벤션센터': 83,\n",
       " '관광단지': 84,\n",
       " '공원': 85,\n",
       " '유원지': 86,\n",
       " '온천/욕장/스파': 87,\n",
       " '테마공원': 88,\n",
       " '유람선/잠수함관광': 89,\n",
       " '이색찜질방': 90,\n",
       " '헬스투어': 91,\n",
       " '컨벤션': 92,\n",
       " '박람회': 93,\n",
       " '기타행사': 94,\n",
       " '전통공연': 95,\n",
       " '대중콘서트': 96,\n",
       " '연극': 97,\n",
       " '뮤지컬': 98,\n",
       " '클래식음악회': 99,\n",
       " '이색거리': 100,\n",
       " '농.산.어촌 체험': 101,\n",
       " '이색체험': 102,\n",
       " '기념탑/기념비/전망대': 103,\n",
       " '유명건물': 104,\n",
       " '동상': 105,\n",
       " '다리/대교': 106,\n",
       " '분수': 107,\n",
       " '터널': 108,\n",
       " '기타': 109,\n",
       " '식음료': 110,\n",
       " '발전소': 111,\n",
       " '모텔': 112,\n",
       " '한옥스테이': 113,\n",
       " '펜션': 114,\n",
       " '게스트하우스': 115,\n",
       " '홈스테이': 116,\n",
       " '콘도미니엄': 117,\n",
       " '민박': 118,\n",
       " '유스호스텔': 119,\n",
       " '서비스드레지던스': 120,\n",
       " '전문상가': 121,\n",
       " '5일장': 122,\n",
       " '상설시장': 123,\n",
       " '공예,공방': 124,\n",
       " '백화점': 125,\n",
       " '면세점': 126,\n",
       " '특산물판매점': 127}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_encoder = {v : i for i, v in enumerate(label_df.loc[:, 'cat3'].values)}\n",
    "cat_encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ae5764",
   "metadata": {},
   "source": [
    "# FSL에 학습 규격에 맞춰서 이미지 이동"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ed732a",
   "metadata": {},
   "source": [
    "### 경로 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b36218c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = './data/fsl_img'\n",
    "os.makedirs(root_path, exist_ok=True)\n",
    "\n",
    "for i, label_name in enumerate(label_df['cat3'].values) :\n",
    "    fold_path = os.path.join(root_path, str(i))#label_name)\n",
    "    os.makedirs(fold_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f886529",
   "metadata": {},
   "source": [
    "### 이미지 이동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "365a09e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 17345/17345 [00:18<00:00, 955.26it/s]\n"
     ]
    }
   ],
   "source": [
    "# df.iloc[0]\n",
    "source_root_path = './data'\n",
    "dest_root_path = './data/fsl_img'\n",
    "\n",
    "for i in tqdm(range(len(df))):\n",
    "    img_path = os.path.join(source_root_path, df.iloc[i]['img_path'])\n",
    "    label = cat_encoder[df.iloc[i]['cat3']] #df.iloc[i]['cat3'] \n",
    "    img_name = df.iloc[i]['id']\n",
    "    dest_path = os.path.join(dest_root_path, str(label), img_name+'.jpg')\n",
    "    \n",
    "    # copy\n",
    "    shutil.copyfile(img_path, dest_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5daec4",
   "metadata": {},
   "source": [
    "# FSL에 이용하는 json 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "64a3e00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "import json\n",
    "\n",
    "fsl_t = defaultdict(list)\n",
    "fsl_v = defaultdict(list)\n",
    "\n",
    "vaild_pick = random.sample([i for i in range(128)], 26)\n",
    "\n",
    "path = './data/fsl_img/*'\n",
    "label_list = glob(path)\n",
    "label_list.sort(key=lambda x: int(x.split('\\\\')[-1]))\n",
    "\n",
    "\n",
    "\n",
    "for idx, label in enumerate(label_list) :  \n",
    "    if idx in vaild_pick :\n",
    "        fsl_v['class_roots'].append(label)\n",
    "        fsl_v['class_names'].append(label.split('\\\\')[-1])\n",
    "\n",
    "    else :\n",
    "        fsl_t['class_roots'].append(label)\n",
    "        fsl_t['class_names'].append(label.split('\\\\')[-1])\n",
    "\n",
    "    \n",
    "with open('./data/fsl_train.json', 'w') as f:\n",
    "    json.dump(fsl_t, f, indent=2)\n",
    "    \n",
    "with open('./data/fsl_valid.json', 'w') as f:\n",
    "    json.dump(fsl_v, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a66089",
   "metadata": {},
   "source": [
    "# FSL configuration 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "239211ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import random\n",
    "from statistics import mean\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "import timm\n",
    "import os\n",
    "\n",
    "from easyfsl.methods.utils import evaluate\n",
    "from easydict import EasyDict\n",
    "\n",
    "args = EasyDict({'n_way' : 4, \n",
    "                 'n_shot' : 4, \n",
    "                 'n_query' : 4, \n",
    "                 'n_workers' : 6, \n",
    "                 'DEVICE' : \"cuda\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d557635c",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "067c9ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from easyfsl.datasets import CUB, CUSTOM\n",
    "from easyfsl.samplers import TaskSampler\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "n_tasks_per_epoch = 100\n",
    "n_validation_tasks = 100\n",
    "\n",
    "\n",
    "\n",
    "train_set = CUSTOM(split=\"data/fsl_train\", image_size=224 ,training=True)\n",
    "val_set = CUSTOM(split=\"data/fsl_valid\", image_size=224, training=False)\n",
    "\n",
    "train_sampler = TaskSampler(\n",
    "    train_set, \n",
    "    n_way=args.n_way, \n",
    "    n_shot=args.n_shot, \n",
    "    n_query=args.n_query, \n",
    "    n_tasks=n_tasks_per_epoch\n",
    ")\n",
    "val_sampler = TaskSampler(\n",
    "    val_set, \n",
    "    n_way=args.n_way, \n",
    "    n_shot=args.n_shot, \n",
    "    n_query=args.n_query, \n",
    "    n_tasks=n_validation_tasks\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_set,\n",
    "    batch_sampler=train_sampler,\n",
    "    num_workers=args.n_workers,\n",
    "    pin_memory=True,\n",
    "    collate_fn=train_sampler.episodic_collate_fn,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_set,\n",
    "    batch_sampler=val_sampler,\n",
    "    num_workers=args.n_workers,\n",
    "    pin_memory=True,\n",
    "    collate_fn=val_sampler.episodic_collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9acd22",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47c69e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module) :\n",
    "    def __init__(self, name='efficientnetv2_rw_m', num_classes=0)  :\n",
    "        super(CNN, self).__init__()\n",
    "        self.model = timm.create_model(name, pretrained=True, num_classes=num_classes, global_pool='')\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.flatten = nn.Flatten(1)\n",
    "        \n",
    "    def forward(self, x) :\n",
    "        x = self.model.forward_features(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.flatten(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47083586",
   "metadata": {},
   "outputs": [],
   "source": [
    "from easyfsl.methods import PrototypicalNetworks, FewShotClassifier, TIM, RelationNetworks\n",
    "\n",
    "convolutional_network = CNN().to(args.DEVICE)\n",
    "few_shot_classifier = PrototypicalNetworks(convolutional_network, use_softmax=True).to(args.DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3b88e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed4c8b24",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb931831",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import SGD, Optimizer, AdamW\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "n_epochs = 8\n",
    "scheduler_milestones = [3, 6]\n",
    "scheduler_gamma = 0.1\n",
    "learning_rate = 1e-2\n",
    "\n",
    "\n",
    "train_optimizer = SGD(\n",
    "    few_shot_classifier.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4\n",
    ")\n",
    "\n",
    "\n",
    "train_scheduler = MultiStepLR(\n",
    "    train_optimizer,\n",
    "    milestones=scheduler_milestones,\n",
    "    gamma=scheduler_gamma,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9be0f198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_epoch(\n",
    "    model: FewShotClassifier, data_loader: DataLoader, optimizer: Optimizer\n",
    "):\n",
    "    all_loss = []\n",
    "    model.train()\n",
    "    with tqdm(\n",
    "        enumerate(data_loader), total=len(data_loader), desc=\"Training\"\n",
    "    ) as tqdm_train:\n",
    "        for episode_index, (\n",
    "            support_images,\n",
    "            support_labels,\n",
    "            query_images,\n",
    "            query_labels,\n",
    "            _,\n",
    "        ) in tqdm_train:\n",
    "            optimizer.zero_grad()\n",
    "            model.process_support_set(\n",
    "                support_images.to(args.DEVICE), support_labels.to(args.DEVICE)\n",
    "            )\n",
    "            classification_scores = model(query_images.to(args.DEVICE))\n",
    "\n",
    "            loss = criterion(classification_scores, query_labels.to(args.DEVICE))\n",
    "#             loss.requires_grad_(True)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            all_loss.append(loss.item())\n",
    "\n",
    "            tqdm_train.set_postfix(loss=mean(all_loss))\n",
    "\n",
    "    return mean(all_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61b989e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████| 100/100 [00:53<00:00,  1.87it/s, loss=1.25]\n",
      "Validation: 100%|████████████████████████████████████████████████████| 100/100 [00:14<00:00,  6.76it/s, accuracy=0.661]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ding ding ding! We found a new best model!\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████| 100/100 [00:50<00:00,  1.96it/s, loss=1.19]\n",
      "Validation: 100%|████████████████████████████████████████████████████| 100/100 [00:14<00:00,  6.82it/s, accuracy=0.666]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ding ding ding! We found a new best model!\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████| 100/100 [00:51<00:00,  1.95it/s, loss=1.14]\n",
      "Validation: 100%|████████████████████████████████████████████████████| 100/100 [00:14<00:00,  6.81it/s, accuracy=0.683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ding ding ding! We found a new best model!\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████| 100/100 [00:53<00:00,  1.89it/s, loss=1.12]\n",
      "Validation: 100%|████████████████████████████████████████████████████| 100/100 [00:14<00:00,  6.77it/s, accuracy=0.658]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████| 100/100 [00:52<00:00,  1.92it/s, loss=1.11]\n",
      "Validation: 100%|████████████████████████████████████████████████████| 100/100 [00:15<00:00,  6.57it/s, accuracy=0.704]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ding ding ding! We found a new best model!\n",
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████| 100/100 [00:52<00:00,  1.89it/s, loss=1.1]\n",
      "Validation: 100%|████████████████████████████████████████████████████| 100/100 [00:14<00:00,  6.67it/s, accuracy=0.698]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████| 100/100 [00:52<00:00,  1.90it/s, loss=1.1]\n",
      "Validation: 100%|████████████████████████████████████████████████████| 100/100 [00:15<00:00,  6.65it/s, accuracy=0.709]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ding ding ding! We found a new best model!\n",
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████| 100/100 [00:52<00:00,  1.91it/s, loss=1.09]\n",
      "Validation: 100%|████████████████████████████████████████████████████| 100/100 [00:15<00:00,  6.61it/s, accuracy=0.696]\n"
     ]
    }
   ],
   "source": [
    "from easyfsl.methods.utils import evaluate\n",
    "\n",
    "start_e = 0\n",
    "best_e = None\n",
    "resum = False\n",
    "model_save_path = './ckpt/fsl/224_effi2_m'\n",
    "os.makedirs(model_save_path, exist_ok=True)\n",
    "\n",
    "tb_logs_dir = Path(\".\")\n",
    "tb_writer = SummaryWriter(log_dir='./tensorboard/fsl_effi2_m')\n",
    "\n",
    "\n",
    "best_state = few_shot_classifier.state_dict()\n",
    "if resum == True : \n",
    "    fsl_checkpoint = torch.load(os.paht.join(model_save_path,'2E_model.pt'))\n",
    "    few_shot_classifier.load_state_dict(fsl_checkpoint[\"model_state_dict\"])\n",
    "    train_optimizer.load_state_dict(fsl_checkpoint['optimizer_state_dict'])\n",
    "    start_e = fsl_checkpoint[\"epoch\"]\n",
    "    \n",
    "best_validation_accuracy = 0.0\n",
    "for epoch in range(start_e, n_epochs):\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    average_loss = training_epoch(few_shot_classifier, train_loader, train_optimizer)\n",
    "    validation_accuracy = evaluate(\n",
    "        few_shot_classifier, val_loader, device=args.DEVICE, tqdm_prefix=\"Validation\"\n",
    "    )\n",
    "\n",
    "    if validation_accuracy > best_validation_accuracy:\n",
    "        best_validation_accuracy = validation_accuracy\n",
    "        print(\"Ding ding ding! We found a new best model!\")\n",
    "        best_e = epoch\n",
    "        torch.save({\n",
    "                \"epoch\" : epoch,\n",
    "                \"model_state_dict\" : best_state,\n",
    "                \"optimizer_state_dict\" : train_optimizer.state_dict()\n",
    "            }, os.path.join(model_save_path, str(epoch)+'E_model.pt'))\n",
    "    \n",
    "\n",
    "    tb_writer.add_scalar(\"Train/loss\", average_loss, epoch)\n",
    "    tb_writer.add_scalar(\"Val/acc\", validation_accuracy, epoch)\n",
    "\n",
    "    # Warn the scheduler that we did an epoch\n",
    "    # so it knows when to decrease the learning rate\n",
    "    train_scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff70b0a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9950f172",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
