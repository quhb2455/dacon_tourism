{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de613819",
   "metadata": {},
   "source": [
    "# Few-shot Learning 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd6c625",
   "metadata": {},
   "source": [
    "### 적용한 이유\n",
    "- 데이터의 라벨이 굉장히 세분화 되어 있음\n",
    "- 이전 경진 대회에서 Few shot Learning을 공부 했고 당시 데이터셋과 주어진 데이터셋의 특징이 유사 했음\n",
    "    - 라벨이 세분화 되어 있다는 특징이 유사했음\n",
    "- Supervised Learning으로는 성능 개선의 한계가 있음\n",
    "- 과제 pdf 파일에 설명되어 있는 쇼핑몰 데이터의 특성이 Few shot learning과 잘 맞다고 생각했음\n",
    "- Training 데이터의 개수가 클래스 별로 동일함\n",
    "\n",
    "### Fine Tuning 진행\n",
    "- Transductive Information Maximization을 적용한 Fine Tuning 진행\n",
    "    - Public set으로 Pretraining 후 주어진 데이터셋에 FineTuning 함\n",
    "    - Fine Tuning 후 점수 하락이 생겼음\n",
    "    - 모델의 Weight를 업데이트 해주는 방식이 아니라 Support set feature map을 업데이트 해주는 방식으로 진행\n",
    "    \n",
    "### RandAug 적용\n",
    "- data augmentation은 일반화 능력을 높여준다고 알려져 있기 때문에 사용\n",
    "- A CLOSER LOOK AT FEW-SHOT CLASSIFICATION 논문에서도 random crop, flip, color jitter등을 사용했음\n",
    "- 적용 시 성능엔 큰 차이가 없었음\n",
    "\n",
    "### Top - k 에 대한 2번의 Inference로 성능 개선\n",
    "- 방법 \n",
    "    1. 첫 번째 Inference로 입력 Image에 대한 Top - 5 추출\n",
    "    2. 추출한 Top - 5에 대해 두 번째 Inference 진행\n",
    "- 적용 이유\n",
    "    - python package(easyfsl)에서 제공하는 Evaluation 코드는 랜덤하게 뽑은 데이터를 Support set과 Query set 모두에 활용함\n",
    "    - Query set의 라벨이 Support set에 속할 경우 정확도가 높게 나오는 것을 확인\n",
    "    - 첫 번째로 뽑은 Top - 5에 대해서 다시 Inference를 진행할 경우 2순위나 3순위로 밀려난 데이터를 1순위로 끌어올 수 있지 않을까 생각했음\n",
    "- 결과\n",
    "    - Top - 1 Accuracy 기준 약 3퍼센트 개선함\n",
    "        - 0.5212 -> 0.5598 \n",
    "    - Top - k 를 구성하는 class가 입력 class와 더욱 유사한 class로 구성됨\n",
    "    - 2, 3순위로 밀려난 Class를 1순위로 끌어 올림\n",
    "        - 7개의 라벨이 Top-1에 속하지 못했음, 적용 후에는 Test set을 구성하는 모든 Class의 Top 1에 속하게 됨\n",
    "            - fsl_multi_infer.ipynb 와 fsl_inference.ipynb 참고\n",
    "    - Inference 횟수가 늘었기 때문에 속도가 약 2.5배 느려짐\n",
    "    \n",
    "### reference\n",
    "- A CLOSER LOOK AT FEW-SHOT CLASSIFICATION\n",
    "    - https://arxiv.org/pdf/1904.04232.pdf\n",
    "- Prototypical Networks for Few-shot Learning\n",
    "    - https://arxiv.org/pdf/1703.05175.pdf\n",
    "- Transductive Information Maximization For Few-Shot Learning\n",
    "    - https://arxiv.org/pdf/2008.11297.pdf\n",
    "- easy-few-shot-learning\n",
    "    - https://github.com/sicara/easy-few-shot-learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e293c5d",
   "metadata": {},
   "source": [
    "#  Create Json\n",
    "- json 파일 명 변경 금지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22b3a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train set\n",
    "fsl = defaultdict(list)\n",
    "\n",
    "path = 'data/train/*'\n",
    "label_list = glob(path)\n",
    "label_list.sort(key=lambda x: int(x.split('\\\\')[-1]))\n",
    "\n",
    "for label in label_list :  \n",
    "    fsl['class_roots'].append(label)\n",
    "    fsl['class_names'].append(label.split('\\\\')[-1])\n",
    "\n",
    "with open('data/train.json', 'w') as f:\n",
    "    json.dump(fsl, f, indent=2)\n",
    "\n",
    "    \n",
    "# test set\n",
    "fsl = defaultdict(list)\n",
    "\n",
    "path = 'data/test/*'\n",
    "label_list = glob(path)\n",
    "label_list.sort(key=lambda x: int(x.split('\\\\')[-1]))\n",
    "\n",
    "for label in label_list :  \n",
    "    fsl['class_roots'].append(label)\n",
    "    fsl['class_names'].append(label.split('\\\\')[-1])\n",
    "    \n",
    "with open('data/test.json', 'w') as f:\n",
    "    json.dump(fsl, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8970f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import random\n",
    "from statistics import mean\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "import timm\n",
    "import os\n",
    "\n",
    "from easyfsl.methods.utils import evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33b51106",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 0\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "726cdb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_way = 5\n",
    "n_shot = 6\n",
    "n_query = 4\n",
    "\n",
    "DEVICE = \"cuda\"\n",
    "n_workers = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18847ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from easyfsl.datasets import CUB, CUSTOM\n",
    "from easyfsl.samplers import TaskSampler\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "n_tasks_per_epoch = 500\n",
    "n_validation_tasks = 100\n",
    "\n",
    "# train_set = CUB(split=\"train\", training=True)\n",
    "# val_set = CUB(split=\"val\", training=False)\n",
    "\n",
    "train_set = CUSTOM(split=\"data/train\", image_size=224 ,training=True)\n",
    "val_set = CUSTOM(split=\"data/test\", image_size=224, training=False)\n",
    "\n",
    "train_sampler = TaskSampler(\n",
    "    train_set, n_way=n_way, n_shot=n_shot, n_query=n_query, n_tasks=n_tasks_per_epoch\n",
    ")\n",
    "val_sampler = TaskSampler(\n",
    "    val_set, n_way=n_way, n_shot=n_shot, n_query=n_query, n_tasks=n_validation_tasks\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_set,\n",
    "    batch_sampler=train_sampler,\n",
    "    num_workers=n_workers,\n",
    "    pin_memory=True,\n",
    "    collate_fn=train_sampler.episodic_collate_fn,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_set,\n",
    "    batch_sampler=val_sampler,\n",
    "    num_workers=n_workers,\n",
    "    pin_memory=True,\n",
    "    collate_fn=val_sampler.episodic_collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b01fd471",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# timm.list_models(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0103d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module) :\n",
    "    def __init__(self, name='efficientnet_b0', num_classes=0)  :\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.model = timm.create_model(name, pretrained=True, num_classes=num_classes)\n",
    "        \n",
    "    def forward(self, x) :\n",
    "        return self.model(x)\n",
    "#         return self.model.forward_features(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0ca4c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from easyfsl.methods import PrototypicalNetworks, FewShotClassifier, TIM, RelationNetworks\n",
    "\n",
    "convolutional_network = CNN()\n",
    "# model_checkpoint = torch.load('./fsl_model/pretrained_effi_b0/9E_model.pt')\n",
    "# convolutional_network.load_state_dict(model_checkpoint[\"model_state_dict\"], strict=False)\n",
    "\n",
    "# few_shot_classifier = PrototypicalNetworks(convolutional_network).to(DEVICE)\n",
    "few_shot_classifier = PrototypicalNetworks(convolutional_network, use_softmax=True).to(DEVICE)\n",
    "\n",
    "# few_shot_classifier = TIM(convolutional_network).to(DEVICE)\n",
    "# few_shot_classifier = RelationNetworks(convolutional_network).to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5900aed8",
   "metadata": {},
   "source": [
    "#### Load Pretrained Model to few shot model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a65989f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fsm_checkpoint = torch.load('./fsl_model/publicset_randaug_224_effi_0/13E_model.pt')\n",
    "# few_shot_classifier.load_state_dict(fsm_checkpoint[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35a44ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import SGD, Optimizer, AdamW\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "LOSS_FUNCTION = nn.CrossEntropyLoss()\n",
    "\n",
    "n_epochs = 8\n",
    "scheduler_milestones = [3, 6]\n",
    "scheduler_gamma = 0.1\n",
    "learning_rate = 1e-2\n",
    "\n",
    "\n",
    "train_optimizer = SGD(\n",
    "    few_shot_classifier.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4\n",
    ")\n",
    "# train_optimizer = AdamW(\n",
    "#     few_shot_classifier.parameters(), lr=learning_rate, weight_decay=5e-4\n",
    "# )\n",
    "\n",
    "train_scheduler = MultiStepLR(\n",
    "    train_optimizer,\n",
    "    milestones=scheduler_milestones,\n",
    "    gamma=scheduler_gamma,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "435b6db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_epoch(\n",
    "    model: FewShotClassifier, data_loader: DataLoader, optimizer: Optimizer\n",
    "):\n",
    "    all_loss = []\n",
    "    model.train()\n",
    "    with tqdm(\n",
    "        enumerate(data_loader), total=len(data_loader), desc=\"Training\"\n",
    "    ) as tqdm_train:\n",
    "        for episode_index, (\n",
    "            support_images,\n",
    "            support_labels,\n",
    "            query_images,\n",
    "            query_labels,\n",
    "            _,\n",
    "        ) in tqdm_train:\n",
    "            optimizer.zero_grad()\n",
    "            model.process_support_set(\n",
    "                support_images.to(DEVICE), support_labels.to(DEVICE)\n",
    "            )\n",
    "            classification_scores = model(query_images.to(DEVICE))\n",
    "\n",
    "            loss = LOSS_FUNCTION(classification_scores, query_labels.to(DEVICE))\n",
    "#             loss.requires_grad_(True)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            all_loss.append(loss.item())\n",
    "\n",
    "            tqdm_train.set_postfix(loss=mean(all_loss))\n",
    "\n",
    "    return mean(all_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbae69e9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████| 500/500 [01:41<00:00,  4.93it/s, loss=1.1]\n",
      "Validation: 100%|████████████████████████████████████████████████████| 100/100 [00:07<00:00, 13.92it/s, accuracy=0.904]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ding ding ding! We found a new best model!\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████| 500/500 [01:38<00:00,  5.10it/s, loss=0.973]\n",
      "Validation: 100%|████████████████████████████████████████████████████| 100/100 [00:07<00:00, 14.26it/s, accuracy=0.907]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ding ding ding! We found a new best model!\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████| 500/500 [01:37<00:00,  5.11it/s, loss=0.947]\n",
      "Validation: 100%|████████████████████████████████████████████████████| 100/100 [00:06<00:00, 14.63it/s, accuracy=0.909]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ding ding ding! We found a new best model!\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████| 500/500 [01:37<00:00,  5.10it/s, loss=0.937]\n",
      "Validation: 100%|████████████████████████████████████████████████████| 100/100 [00:06<00:00, 14.78it/s, accuracy=0.904]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████| 500/500 [01:38<00:00,  5.10it/s, loss=0.935]\n",
      "Validation: 100%|████████████████████████████████████████████████████| 100/100 [00:06<00:00, 14.67it/s, accuracy=0.901]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████| 500/500 [01:37<00:00,  5.10it/s, loss=0.935]\n",
      "Validation: 100%|████████████████████████████████████████████████████| 100/100 [00:06<00:00, 14.79it/s, accuracy=0.911]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ding ding ding! We found a new best model!\n",
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████| 500/500 [01:38<00:00,  5.10it/s, loss=0.936]\n",
      "Validation: 100%|████████████████████████████████████████████████████| 100/100 [00:06<00:00, 14.58it/s, accuracy=0.896]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████████████████████████████████████████████████████| 500/500 [01:37<00:00,  5.10it/s, loss=0.933]\n",
      "Validation: 100%|████████████████████████████████████████████████████| 100/100 [00:07<00:00, 13.46it/s, accuracy=0.898]\n"
     ]
    }
   ],
   "source": [
    "from easyfsl.methods.utils import evaluate\n",
    "\n",
    "start_e = 0\n",
    "best_e = None\n",
    "resum = False\n",
    "model_save_path = './submission/fsl_224_effi_b0/'\n",
    "os.makedirs(model_save_path, exist_ok=True)\n",
    "\n",
    "tb_logs_dir = Path(\".\")\n",
    "tb_writer = SummaryWriter(log_dir=str(model_save_path))\n",
    "\n",
    "\n",
    "best_state = few_shot_classifier.state_dict()\n",
    "if resum == True : \n",
    "    fsl_checkpoint = torch.load(os.paht.join(model_save_path,'2E_model.pt'))\n",
    "    few_shot_classifier.load_state_dict(fsl_checkpoint[\"model_state_dict\"])\n",
    "    train_optimizer.load_state_dict(fsl_checkpoint['optimizer_state_dict'])\n",
    "    start_e = fsl_checkpoint[\"epoch\"]\n",
    "    \n",
    "best_validation_accuracy = 0.0\n",
    "for epoch in range(start_e, n_epochs):\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    average_loss = training_epoch(few_shot_classifier, train_loader, train_optimizer)\n",
    "    validation_accuracy = evaluate(\n",
    "        few_shot_classifier, val_loader, device=DEVICE, tqdm_prefix=\"Validation\"\n",
    "    )\n",
    "\n",
    "    if validation_accuracy > best_validation_accuracy:\n",
    "        best_validation_accuracy = validation_accuracy\n",
    "        print(\"Ding ding ding! We found a new best model!\")\n",
    "        best_e = epoch\n",
    "        torch.save({\n",
    "                \"epoch\" : epoch,\n",
    "                \"model_state_dict\" : best_state,\n",
    "                \"optimizer_state_dict\" : train_optimizer.state_dict()\n",
    "            }, os.path.join(model_save_path, str(epoch)+'E_model.pt'))\n",
    "    \n",
    "\n",
    "    tb_writer.add_scalar(\"Train/loss\", average_loss, epoch)\n",
    "    tb_writer.add_scalar(\"Val/acc\", validation_accuracy, epoch)\n",
    "\n",
    "    # Warn the scheduler that we did an epoch\n",
    "    # so it knows when to decrease the learning rate\n",
    "    train_scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0d5a56",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ad85608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fsm_checkpoint = torch.load(os.path.join(model_save_path, f'{best_e}E_model.pt'))\n",
    "few_shot_classifier.load_state_dict(fsm_checkpoint[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cce33b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████| 500/500 [00:33<00:00, 15.07it/s, accuracy=0.891]\n"
     ]
    }
   ],
   "source": [
    "n_way = 5\n",
    "n_shot = 6\n",
    "n_query = 4\n",
    "\n",
    "DEVICE = \"cuda\"\n",
    "n_workers = 6\n",
    "n_validation_tasks = 500 #100\n",
    "\n",
    "val_set = CUSTOM(split=\"data/test\", image_size=224, training=False)\n",
    "\n",
    "val_sampler = TaskSampler(\n",
    "    val_set, n_way=n_way, n_shot=n_shot, n_query=n_query, n_tasks=n_validation_tasks\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_set,\n",
    "    batch_sampler=val_sampler,\n",
    "    num_workers=n_workers,\n",
    "    pin_memory=True,\n",
    "    collate_fn=val_sampler.episodic_collate_fn,\n",
    ")\n",
    "\n",
    "validation_accuracy = evaluate(\n",
    "        few_shot_classifier, val_loader, device=DEVICE, tqdm_prefix=\"Validation\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55389277",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(model_save_path,'score.txt'), 'w') as f :\n",
    "    f.write(str(validation_accuracy)+'\\n')\n",
    "    f.write('n_way : ' + str(n_way)+'\\n')\n",
    "    f.write('n_shot : ' + str(n_shot)+'\\n')\n",
    "    f.write('n_query : ' + str(n_query)+'\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ccc75703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finetuning 시에는 augmentaion 제외 시킴"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "buzzni",
   "language": "python",
   "name": "buzzni"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
